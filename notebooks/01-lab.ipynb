{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "873440fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e246093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "\n",
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff29f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/Projects/End-to-end-Sale-Forecasting\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "374d2f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">[</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'userId'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'sunt aut facere repellat provident occaecati excepturi optio reprehenderit'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'body'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">quas totam\\nnostrum rerum est autem sunt rem eveniet architecto'</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'userId'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'qui est esse'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'body'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">nulla'</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'userId'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'id'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'ea molestias quasi exercitationem repellat qui ipsa sit aut'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'body'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">accusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut'</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;0;255;0m[\u001b[0m\n",
       "\u001b[38;2;0;255;0m    \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'userId'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'id'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'title'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[32m'sunt aut facere repellat provident occaecati excepturi optio reprehenderit'\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'body'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[32m'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut \u001b[0m\n",
       "\u001b[32mquas totam\\nnostrum rerum est autem sunt rem eveniet architecto'\u001b[0m\n",
       "\u001b[38;2;0;255;0m    \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m    \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'userId'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'id'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'title'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[32m'qui est esse'\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'body'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[32m'est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat \u001b[0m\n",
       "\u001b[32mblanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi \u001b[0m\n",
       "\u001b[32mnulla'\u001b[0m\n",
       "\u001b[38;2;0;255;0m    \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m    \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'userId'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'id'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'title'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[32m'ea molestias quasi exercitationem repellat qui ipsa sit aut'\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'body'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[32m'et iusto sed quo iure\\nvoluptatem occaecati omnis eligendi aut ad\\nvoluptatem doloribus vel \u001b[0m\n",
       "\u001b[32maccusantium quis pariatur\\nmolestiae porro eius odio et labore et velit aut'\u001b[0m\n",
       "\u001b[38;2;0;255;0m    \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\n",
       "\u001b[1;38;2;0;255;0m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import httpx\n",
    "\n",
    "url: str = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "\n",
    "response = httpx.get(url, timeout=10)\n",
    "response.raise_for_status()  # Raise an error for bad responses\n",
    "console.print(response.json()[:3], style=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd6737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f895fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: No regex match found!\n",
      "WARNING: No regex match found!\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-01-31\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-01\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-02\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-03\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-04\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-05\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-06\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-07\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-08\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-09\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-10\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-11\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-12\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-13\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-14\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-15\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-16\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-17\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-18\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-19\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-20\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-21\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-22\n",
      "2025-09-05 15:27:15 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-23\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-24\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-25\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-26\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-27\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-02-28\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-01\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-02\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-03\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-04\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-05\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-06\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-07\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-08\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-09\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-10\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-11\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-12\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-13\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-14\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-15\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-16\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-17\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-18\n",
      "2025-09-05 15:27:16 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-19\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-20\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-21\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-22\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-23\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-24\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-25\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-26\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-27\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-28\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-29\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-30\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-03-31\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-01\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-02\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-03\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-04\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-05\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-06\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-07\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-08\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-09\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-10\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-11\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-12\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-13\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-14\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-15\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-16\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-17\n",
      "2025-09-05 15:27:17 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-18\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-19\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-20\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-21\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-22\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-23\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-24\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-25\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-26\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-27\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-28\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-29\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-04-30\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-01\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-02\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-03\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-04\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-05\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-06\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-07\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-08\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-09\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-10\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-11\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-12\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-13\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-14\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-15\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-16\n",
      "2025-09-05 15:27:18 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-17\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-18\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-19\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-20\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-21\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-22\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-23\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-24\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-25\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-26\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-27\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-28\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-29\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-30\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-05-31\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-01\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-02\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-03\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-04\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-05\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-06\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-07\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-08\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-09\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-10\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-11\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-12\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-13\n",
      "2025-09-05 15:27:19 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-14\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-15\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-16\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-17\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-18\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-19\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-20\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-21\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-22\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-23\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-24\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-25\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-26\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-27\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-28\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-29\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-06-30\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-01\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-02\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-03\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-04\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-05\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-06\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-07\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-08\n",
      "2025-09-05 15:27:20 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-09\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-10\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-11\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-12\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-13\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-14\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-15\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-16\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-17\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-18\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-19\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-20\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-21\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-22\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-23\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-24\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-25\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-26\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-27\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-28\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-29\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-30\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-07-31\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-01\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-02\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-03\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-04\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-05\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-06\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-07\n",
      "2025-09-05 15:27:21 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-08\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-09\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-10\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-11\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-12\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-13\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-14\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-15\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-16\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-17\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-18\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-19\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-20\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-21\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-22\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-23\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-24\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-25\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-26\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-27\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-28\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-29\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-30\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-08-31\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-01\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-02\n",
      "2025-09-05 15:27:22 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-03\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-04\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-05\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-06\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-07\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-08\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-09\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-10\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-11\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-12\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-13\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-14\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-15\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-16\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-17\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-18\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-19\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-20\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-21\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-22\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-23\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-24\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-25\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-26\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-27\n",
      "2025-09-05 15:27:23 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-28\n",
      "2025-09-05 15:27:24 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-29\n",
      "2025-09-05 15:27:24 - include.utilities.data_gen - [INFO] - Generating data for 2025-09-30\n",
      "2025-09-05 15:27:24 - include.utilities.data_gen - [INFO] - Generated 440 files\n",
      "2025-09-05 15:27:24 - include.utilities.data_gen - [INFO] - Sales files: 160\n",
      "2025-09-05 15:27:24 - include.utilities.data_gen - [INFO] - Output directory: ./data/sales_data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sales': ['./data/sales_data/sales/year=2025/month=02/day=01/sales_2025-02-01.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=02/day=02/sales_2025-02-02.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=02/day=03/sales_2025-02-03.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=02/day=08/sales_2025-02-08.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=02/day=09/sales_2025-02-09.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=02/day=15/sales_2025-02-15.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=02/day=16/sales_2025-02-16.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=02/day=17/sales_2025-02-17.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=02/day=22/sales_2025-02-22.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=02/day=23/sales_2025-02-23.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=01/sales_2025-03-01.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=03/sales_2025-03-03.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=06/sales_2025-03-06.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=07/sales_2025-03-07.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=08/sales_2025-03-08.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=09/sales_2025-03-09.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=14/sales_2025-03-14.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=15/sales_2025-03-15.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=16/sales_2025-03-16.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=22/sales_2025-03-22.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=23/sales_2025-03-23.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=24/sales_2025-03-24.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=28/sales_2025-03-28.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=29/sales_2025-03-29.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=30/sales_2025-03-30.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=03/day=31/sales_2025-03-31.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=03/sales_2025-04-03.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=05/sales_2025-04-05.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=06/sales_2025-04-06.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=07/sales_2025-04-07.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=08/sales_2025-04-08.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=11/sales_2025-04-11.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=12/sales_2025-04-12.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=13/sales_2025-04-13.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=16/sales_2025-04-16.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=18/sales_2025-04-18.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=19/sales_2025-04-19.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=20/sales_2025-04-20.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=21/sales_2025-04-21.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=24/sales_2025-04-24.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=26/sales_2025-04-26.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=27/sales_2025-04-27.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=29/sales_2025-04-29.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=04/day=30/sales_2025-04-30.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=01/sales_2025-05-01.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=02/sales_2025-05-02.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=03/sales_2025-05-03.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=04/sales_2025-05-04.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=05/sales_2025-05-05.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=08/sales_2025-05-08.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=09/sales_2025-05-09.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=10/sales_2025-05-10.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=11/sales_2025-05-11.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=12/sales_2025-05-12.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=13/sales_2025-05-13.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=15/sales_2025-05-15.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=16/sales_2025-05-16.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=17/sales_2025-05-17.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=18/sales_2025-05-18.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=20/sales_2025-05-20.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=21/sales_2025-05-21.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=22/sales_2025-05-22.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=23/sales_2025-05-23.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=24/sales_2025-05-24.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=25/sales_2025-05-25.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=26/sales_2025-05-26.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=27/sales_2025-05-27.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=28/sales_2025-05-28.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=30/sales_2025-05-30.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=05/day=31/sales_2025-05-31.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=01/sales_2025-06-01.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=02/sales_2025-06-02.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=03/sales_2025-06-03.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=04/sales_2025-06-04.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=05/sales_2025-06-05.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=06/sales_2025-06-06.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=07/sales_2025-06-07.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=08/sales_2025-06-08.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=11/sales_2025-06-11.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=12/sales_2025-06-12.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=13/sales_2025-06-13.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=14/sales_2025-06-14.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=15/sales_2025-06-15.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=16/sales_2025-06-16.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=17/sales_2025-06-17.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=19/sales_2025-06-19.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=20/sales_2025-06-20.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=21/sales_2025-06-21.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=22/sales_2025-06-22.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=23/sales_2025-06-23.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=24/sales_2025-06-24.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=25/sales_2025-06-25.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=26/sales_2025-06-26.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=27/sales_2025-06-27.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=28/sales_2025-06-28.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=29/sales_2025-06-29.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=06/day=30/sales_2025-06-30.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=01/sales_2025-07-01.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=02/sales_2025-07-02.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=03/sales_2025-07-03.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=04/sales_2025-07-04.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=05/sales_2025-07-05.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=06/sales_2025-07-06.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=08/sales_2025-07-08.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=09/sales_2025-07-09.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=10/sales_2025-07-10.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=11/sales_2025-07-11.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=12/sales_2025-07-12.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=13/sales_2025-07-13.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=14/sales_2025-07-14.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=15/sales_2025-07-15.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=17/sales_2025-07-17.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=18/sales_2025-07-18.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=19/sales_2025-07-19.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=20/sales_2025-07-20.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=21/sales_2025-07-21.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=22/sales_2025-07-22.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=23/sales_2025-07-23.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=24/sales_2025-07-24.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=26/sales_2025-07-26.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=27/sales_2025-07-27.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=28/sales_2025-07-28.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=07/day=31/sales_2025-07-31.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=01/sales_2025-08-01.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=02/sales_2025-08-02.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=03/sales_2025-08-03.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=04/sales_2025-08-04.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=06/sales_2025-08-06.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=07/sales_2025-08-07.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=08/sales_2025-08-08.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=09/sales_2025-08-09.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=10/sales_2025-08-10.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=11/sales_2025-08-11.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=12/sales_2025-08-12.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=13/sales_2025-08-13.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=14/sales_2025-08-14.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=15/sales_2025-08-15.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=16/sales_2025-08-16.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=17/sales_2025-08-17.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=18/sales_2025-08-18.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=22/sales_2025-08-22.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=23/sales_2025-08-23.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=24/sales_2025-08-24.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=29/sales_2025-08-29.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=30/sales_2025-08-30.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=08/day=31/sales_2025-08-31.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=01/sales_2025-09-01.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=02/sales_2025-09-02.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=03/sales_2025-09-03.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=06/sales_2025-09-06.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=07/sales_2025-09-07.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=08/sales_2025-09-08.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=13/sales_2025-09-13.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=14/sales_2025-09-14.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=20/sales_2025-09-20.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=21/sales_2025-09-21.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=25/sales_2025-09-25.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=26/sales_2025-09-26.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=27/sales_2025-09-27.parquet',\n",
       "  './data/sales_data/sales/year=2025/month=09/day=28/sales_2025-09-28.parquet'],\n",
       " 'inventory': ['./data/sales_data/inventory/year=2025/week=05/inventory_2025-02-02.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=06/inventory_2025-02-09.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=07/inventory_2025-02-16.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=08/inventory_2025-02-23.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=09/inventory_2025-03-02.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=10/inventory_2025-03-09.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=11/inventory_2025-03-16.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=12/inventory_2025-03-23.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=13/inventory_2025-03-30.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=14/inventory_2025-04-06.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=15/inventory_2025-04-13.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=16/inventory_2025-04-20.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=17/inventory_2025-04-27.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=18/inventory_2025-05-04.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=19/inventory_2025-05-11.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=20/inventory_2025-05-18.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=21/inventory_2025-05-25.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=22/inventory_2025-06-01.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=23/inventory_2025-06-08.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=24/inventory_2025-06-15.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=25/inventory_2025-06-22.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=26/inventory_2025-06-29.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=27/inventory_2025-07-06.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=28/inventory_2025-07-13.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=29/inventory_2025-07-20.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=30/inventory_2025-07-27.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=31/inventory_2025-08-03.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=32/inventory_2025-08-10.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=33/inventory_2025-08-17.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=34/inventory_2025-08-24.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=35/inventory_2025-08-31.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=36/inventory_2025-09-07.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=37/inventory_2025-09-14.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=38/inventory_2025-09-21.parquet',\n",
       "  './data/sales_data/inventory/year=2025/week=39/inventory_2025-09-28.parquet'],\n",
       " 'customer_traffic': ['./data/sales_data/customer_traffic/year=2025/month=01/day=31/traffic_2025-01-31.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=01/traffic_2025-02-01.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=02/traffic_2025-02-02.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=03/traffic_2025-02-03.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=04/traffic_2025-02-04.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=05/traffic_2025-02-05.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=06/traffic_2025-02-06.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=07/traffic_2025-02-07.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=08/traffic_2025-02-08.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=09/traffic_2025-02-09.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=10/traffic_2025-02-10.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=11/traffic_2025-02-11.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=12/traffic_2025-02-12.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=13/traffic_2025-02-13.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=14/traffic_2025-02-14.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=15/traffic_2025-02-15.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=16/traffic_2025-02-16.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=17/traffic_2025-02-17.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=18/traffic_2025-02-18.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=19/traffic_2025-02-19.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=20/traffic_2025-02-20.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=21/traffic_2025-02-21.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=22/traffic_2025-02-22.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=23/traffic_2025-02-23.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=24/traffic_2025-02-24.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=25/traffic_2025-02-25.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=26/traffic_2025-02-26.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=27/traffic_2025-02-27.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=02/day=28/traffic_2025-02-28.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=01/traffic_2025-03-01.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=02/traffic_2025-03-02.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=03/traffic_2025-03-03.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=04/traffic_2025-03-04.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=05/traffic_2025-03-05.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=06/traffic_2025-03-06.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=07/traffic_2025-03-07.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=08/traffic_2025-03-08.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=09/traffic_2025-03-09.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=10/traffic_2025-03-10.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=11/traffic_2025-03-11.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=12/traffic_2025-03-12.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=13/traffic_2025-03-13.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=14/traffic_2025-03-14.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=15/traffic_2025-03-15.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=16/traffic_2025-03-16.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=17/traffic_2025-03-17.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=18/traffic_2025-03-18.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=19/traffic_2025-03-19.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=20/traffic_2025-03-20.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=21/traffic_2025-03-21.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=22/traffic_2025-03-22.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=23/traffic_2025-03-23.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=24/traffic_2025-03-24.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=25/traffic_2025-03-25.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=26/traffic_2025-03-26.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=27/traffic_2025-03-27.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=28/traffic_2025-03-28.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=29/traffic_2025-03-29.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=30/traffic_2025-03-30.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=03/day=31/traffic_2025-03-31.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=01/traffic_2025-04-01.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=02/traffic_2025-04-02.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=03/traffic_2025-04-03.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=04/traffic_2025-04-04.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=05/traffic_2025-04-05.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=06/traffic_2025-04-06.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=07/traffic_2025-04-07.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=08/traffic_2025-04-08.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=09/traffic_2025-04-09.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=10/traffic_2025-04-10.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=11/traffic_2025-04-11.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=12/traffic_2025-04-12.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=13/traffic_2025-04-13.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=14/traffic_2025-04-14.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=15/traffic_2025-04-15.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=16/traffic_2025-04-16.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=17/traffic_2025-04-17.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=18/traffic_2025-04-18.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=19/traffic_2025-04-19.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=20/traffic_2025-04-20.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=21/traffic_2025-04-21.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=22/traffic_2025-04-22.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=23/traffic_2025-04-23.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=24/traffic_2025-04-24.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=25/traffic_2025-04-25.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=26/traffic_2025-04-26.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=27/traffic_2025-04-27.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=28/traffic_2025-04-28.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=29/traffic_2025-04-29.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=04/day=30/traffic_2025-04-30.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=01/traffic_2025-05-01.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=02/traffic_2025-05-02.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=03/traffic_2025-05-03.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=04/traffic_2025-05-04.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=05/traffic_2025-05-05.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=06/traffic_2025-05-06.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=07/traffic_2025-05-07.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=08/traffic_2025-05-08.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=09/traffic_2025-05-09.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=10/traffic_2025-05-10.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=11/traffic_2025-05-11.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=12/traffic_2025-05-12.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=13/traffic_2025-05-13.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=14/traffic_2025-05-14.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=15/traffic_2025-05-15.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=16/traffic_2025-05-16.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=17/traffic_2025-05-17.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=18/traffic_2025-05-18.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=19/traffic_2025-05-19.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=20/traffic_2025-05-20.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=21/traffic_2025-05-21.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=22/traffic_2025-05-22.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=23/traffic_2025-05-23.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=24/traffic_2025-05-24.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=25/traffic_2025-05-25.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=26/traffic_2025-05-26.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=27/traffic_2025-05-27.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=28/traffic_2025-05-28.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=29/traffic_2025-05-29.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=30/traffic_2025-05-30.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=05/day=31/traffic_2025-05-31.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=01/traffic_2025-06-01.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=02/traffic_2025-06-02.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=03/traffic_2025-06-03.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=04/traffic_2025-06-04.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=05/traffic_2025-06-05.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=06/traffic_2025-06-06.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=07/traffic_2025-06-07.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=08/traffic_2025-06-08.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=09/traffic_2025-06-09.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=10/traffic_2025-06-10.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=11/traffic_2025-06-11.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=12/traffic_2025-06-12.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=13/traffic_2025-06-13.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=14/traffic_2025-06-14.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=15/traffic_2025-06-15.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=16/traffic_2025-06-16.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=17/traffic_2025-06-17.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=18/traffic_2025-06-18.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=19/traffic_2025-06-19.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=20/traffic_2025-06-20.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=21/traffic_2025-06-21.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=22/traffic_2025-06-22.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=23/traffic_2025-06-23.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=24/traffic_2025-06-24.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=25/traffic_2025-06-25.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=26/traffic_2025-06-26.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=27/traffic_2025-06-27.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=28/traffic_2025-06-28.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=29/traffic_2025-06-29.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=06/day=30/traffic_2025-06-30.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=01/traffic_2025-07-01.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=02/traffic_2025-07-02.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=03/traffic_2025-07-03.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=04/traffic_2025-07-04.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=05/traffic_2025-07-05.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=06/traffic_2025-07-06.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=07/traffic_2025-07-07.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=08/traffic_2025-07-08.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=09/traffic_2025-07-09.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=10/traffic_2025-07-10.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=11/traffic_2025-07-11.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=12/traffic_2025-07-12.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=13/traffic_2025-07-13.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=14/traffic_2025-07-14.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=15/traffic_2025-07-15.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=16/traffic_2025-07-16.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=17/traffic_2025-07-17.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=18/traffic_2025-07-18.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=19/traffic_2025-07-19.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=20/traffic_2025-07-20.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=21/traffic_2025-07-21.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=22/traffic_2025-07-22.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=23/traffic_2025-07-23.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=24/traffic_2025-07-24.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=25/traffic_2025-07-25.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=26/traffic_2025-07-26.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=27/traffic_2025-07-27.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=28/traffic_2025-07-28.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=29/traffic_2025-07-29.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=30/traffic_2025-07-30.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=07/day=31/traffic_2025-07-31.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=01/traffic_2025-08-01.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=02/traffic_2025-08-02.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=03/traffic_2025-08-03.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=04/traffic_2025-08-04.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=05/traffic_2025-08-05.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=06/traffic_2025-08-06.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=07/traffic_2025-08-07.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=08/traffic_2025-08-08.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=09/traffic_2025-08-09.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=10/traffic_2025-08-10.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=11/traffic_2025-08-11.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=12/traffic_2025-08-12.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=13/traffic_2025-08-13.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=14/traffic_2025-08-14.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=15/traffic_2025-08-15.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=16/traffic_2025-08-16.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=17/traffic_2025-08-17.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=18/traffic_2025-08-18.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=19/traffic_2025-08-19.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=20/traffic_2025-08-20.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=21/traffic_2025-08-21.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=22/traffic_2025-08-22.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=23/traffic_2025-08-23.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=24/traffic_2025-08-24.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=25/traffic_2025-08-25.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=26/traffic_2025-08-26.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=27/traffic_2025-08-27.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=28/traffic_2025-08-28.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=29/traffic_2025-08-29.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=30/traffic_2025-08-30.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=08/day=31/traffic_2025-08-31.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=01/traffic_2025-09-01.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=02/traffic_2025-09-02.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=03/traffic_2025-09-03.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=04/traffic_2025-09-04.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=05/traffic_2025-09-05.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=06/traffic_2025-09-06.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=07/traffic_2025-09-07.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=08/traffic_2025-09-08.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=09/traffic_2025-09-09.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=10/traffic_2025-09-10.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=11/traffic_2025-09-11.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=12/traffic_2025-09-12.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=13/traffic_2025-09-13.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=14/traffic_2025-09-14.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=15/traffic_2025-09-15.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=16/traffic_2025-09-16.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=17/traffic_2025-09-17.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=18/traffic_2025-09-18.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=19/traffic_2025-09-19.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=20/traffic_2025-09-20.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=21/traffic_2025-09-21.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=22/traffic_2025-09-22.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=23/traffic_2025-09-23.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=24/traffic_2025-09-24.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=25/traffic_2025-09-25.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=26/traffic_2025-09-26.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=27/traffic_2025-09-27.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=28/traffic_2025-09-28.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=29/traffic_2025-09-29.parquet',\n",
       "  './data/sales_data/customer_traffic/year=2025/month=09/day=30/traffic_2025-09-30.parquet'],\n",
       " 'promotions': ['./data/sales_data/promotions/promotions.parquet'],\n",
       " 'store_events': ['./data/sales_data/store_events/events.parquet']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from include.config import app_settings\n",
    "from include.utilities.data_gen import RealisticSalesDataGenerator\n",
    "\n",
    "gen_data = RealisticSalesDataGenerator(start_date=\"2025-01-31\", end_date=\"2025-09-30\", seed=123)\n",
    "file_paths: dict[str, Any] = gen_data.generate_sales_data(output_dir=\"./data/sales_data\")\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a191a6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_files = sum(len(paths) for paths in file_paths.values())\n",
    "total_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c22120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sales data from multiple files...\n",
      "  Loaded 10 files...\n",
      "  Loaded 20 files...\n",
      "  Loaded 30 files...\n",
      "  Loaded 40 files...\n",
      "  Loaded 50 files...\n",
      "Combined sales data shape: (174, 10)\n",
      "Final training data shape: (174, 13)\n",
      "Columns: ['date', 'store_id', 'product_id', 'category', 'quantity_sold', 'sales', 'cost', 'profit', 'discount_percent', 'unit_price', 'has_promotion', 'customer_traffic', 'is_holiday']\n",
      "WARNING: No regex match found!\n",
      "2025-09-05 15:56:26 - include.utilities.feature_engineering - [INFO] - Starting feature engineering pipeline\n",
      "2025-09-05 15:56:26 - include.utilities.feature_engineering - [INFO] - Created 7 lag features\n",
      "2025-09-05 15:56:26 - include.utilities.feature_engineering - [INFO] - Feature engineering pipeline completed. 41 total features.\n",
      "2025-09-05 15:56:26 - include.ml.trainer - [INFO] - Data split - {\"train_size\": 60, \"validation_size\": 8, \"test_size\": 18}\n",
      "Train shape: (60, 41), Val shape: (8, 41), Test shape: (18, 41)\n"
     ]
    }
   ],
   "source": [
    "# Convert to Polars\n",
    "import mlflow\n",
    "from polars.dataframe.frame import DataFrame\n",
    "\n",
    "from include.ml.trainer import ModelTrainer\n",
    "\n",
    "print(\"Loading sales data from multiple files...\")\n",
    "sales_dfs: list[pl.DataFrame] = []\n",
    "max_files: int = 50\n",
    "skipped_sales: int = 0\n",
    "\n",
    "for i, sales_file in enumerate(file_paths[\"sales\"][:max_files]):\n",
    "    try:\n",
    "        df = pl.read_parquet(sales_file)\n",
    "        sales_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        skipped_sales += 1\n",
    "        print(f\"  Skipping unreadable sales file {sales_file}: {e}\")\n",
    "        continue\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Loaded {i + 1} files...\")\n",
    "if not sales_dfs:\n",
    "    raise ValueError(\"No readable sales parquet files were loaded; aborting training\")\n",
    "\n",
    "sales_df = pl.concat(sales_dfs)\n",
    "print(f\"Combined sales data shape: {sales_df.shape}\")\n",
    "daily_sales: DataFrame = (\n",
    "    sales_df.group_by([\"date\", \"store_id\", \"product_id\", \"category\"])\n",
    "    .agg(\n",
    "        pl.col(\"quantity_sold\").sum(),\n",
    "        pl.col(\"revenue\").sum().alias(\"sales\"),\n",
    "        pl.col(\"cost\").sum(),\n",
    "        pl.col(\"profit\").sum(),\n",
    "        pl.col(\"discount_percent\").mean(),\n",
    "        pl.col(\"unit_price\").mean(),\n",
    "    )\n",
    "    .sort(\"date\", \"store_id\")\n",
    ")\n",
    "\n",
    "if file_paths.get(\"promotions\"):\n",
    "    try:\n",
    "        promo_df = pl.read_parquet(file_paths[\"promotions\"][0])\n",
    "        promo_summary = (\n",
    "            promo_df.group_by([\"date\", \"product_id\"])\n",
    "            .agg(pl.col(\"discount_percent\").max())\n",
    "            .with_columns(pl.lit(1).cast(pl.Int8).alias(\"has_promotion\"))\n",
    "        )\n",
    "        daily_sales = daily_sales.join(\n",
    "            promo_summary.select([\"date\", \"product_id\", \"has_promotion\"]),\n",
    "            on=[\"date\", \"product_id\"],\n",
    "            how=\"left\",\n",
    "        ).with_columns(pl.col(\"has_promotion\").fill_null(0))\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping promotions merge due to error: {e}\")\n",
    "\n",
    "if file_paths.get(\"customer_traffic\"):\n",
    "    traffic_dfs: list[pl.DataFrame] = []\n",
    "    skipped_traffic: int = 0\n",
    "\n",
    "    for traffic_file in file_paths[\"customer_traffic\"][:10]:\n",
    "        try:\n",
    "            traffic_dfs.append(pl.read_parquet(traffic_file))\n",
    "        except Exception as e:\n",
    "            skipped_traffic += 1\n",
    "            print(f\"  Skipping unreadable traffic file {traffic_file}: {e}\")\n",
    "\n",
    "    if traffic_dfs:\n",
    "        traffic_df = pl.concat(traffic_dfs)\n",
    "        traffic_summary = traffic_df.group_by([\"date\", \"store_id\"]).agg(\n",
    "            pl.col(\"customer_traffic\").sum(), pl.col(\"is_holiday\").max()\n",
    "        )\n",
    "        daily_sales = daily_sales.join(\n",
    "            traffic_summary,\n",
    "            on=[\"date\", \"store_id\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "    else:\n",
    "        print(\"No readable traffic files; skipping merge\")\n",
    "print(f\"Final training data shape: {daily_sales.shape}\")\n",
    "print(f\"Columns: {daily_sales.columns}\")\n",
    "\n",
    "trainer = ModelTrainer()\n",
    "store_daily_sales: DataFrame = (\n",
    "    daily_sales.group_by([\"date\", \"store_id\"])\n",
    "    .agg(\n",
    "        pl.col(\"sales\").sum(),\n",
    "        pl.col(\"quantity_sold\").sum(),\n",
    "        pl.col(\"profit\").sum(),\n",
    "        pl.col(\"has_promotion\").mean(),\n",
    "        pl.col(\"customer_traffic\").first(),\n",
    "        pl.col(\"is_holiday\").first(),\n",
    "    )\n",
    "    .with_columns(pl.col(\"date\").cast(pl.Date))\n",
    ")\n",
    "train_df, val_df, test_df = trainer.prepare_data(\n",
    "    store_daily_sales,\n",
    "    target_col=\"sales\",\n",
    "    group_cols=[\"store_id\"],\n",
    "    categorical_cols=[\"store_id\"],\n",
    ")\n",
    "print(f\"Train shape: {train_df.shape}, Val shape: {val_df.shape}, Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bbfc8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-05 15:56:26 - include.utilities.mlflow_utils - [INFO] - Started MLflow run: ba4fdb57e96742fa8000536ea248c5aa\n",
      "2025-09-05 15:56:26 - include.ml.trainer - [INFO] - Training XGBoost model\n",
      "[0]\tvalidation_0-rmse:62.68329\n",
      "[1]\tvalidation_0-rmse:55.46352\n",
      "[2]\tvalidation_0-rmse:51.54056\n",
      "[3]\tvalidation_0-rmse:45.53690\n",
      "[4]\tvalidation_0-rmse:42.28120\n",
      "[5]\tvalidation_0-rmse:39.15963\n",
      "[6]\tvalidation_0-rmse:36.29725\n",
      "[7]\tvalidation_0-rmse:33.63027\n",
      "[8]\tvalidation_0-rmse:30.93414\n",
      "[9]\tvalidation_0-rmse:28.67686\n",
      "[10]\tvalidation_0-rmse:26.89091\n",
      "[11]\tvalidation_0-rmse:25.05359\n",
      "[12]\tvalidation_0-rmse:23.38517\n",
      "[13]\tvalidation_0-rmse:21.83391\n",
      "[14]\tvalidation_0-rmse:20.36703\n",
      "[15]\tvalidation_0-rmse:19.08786\n",
      "[16]\tvalidation_0-rmse:17.95905\n",
      "[17]\tvalidation_0-rmse:16.84690\n",
      "[18]\tvalidation_0-rmse:15.87859\n",
      "[19]\tvalidation_0-rmse:14.94017\n",
      "[20]\tvalidation_0-rmse:14.10110\n",
      "[21]\tvalidation_0-rmse:13.41335\n",
      "[22]\tvalidation_0-rmse:12.75128\n",
      "[23]\tvalidation_0-rmse:12.13010\n",
      "[24]\tvalidation_0-rmse:11.57988\n",
      "[25]\tvalidation_0-rmse:11.03472\n",
      "[26]\tvalidation_0-rmse:10.56557\n",
      "[27]\tvalidation_0-rmse:10.12896\n",
      "[28]\tvalidation_0-rmse:9.74104\n",
      "[29]\tvalidation_0-rmse:8.93780\n",
      "[30]\tvalidation_0-rmse:8.59957\n",
      "[31]\tvalidation_0-rmse:8.29810\n",
      "[32]\tvalidation_0-rmse:8.03450\n",
      "[33]\tvalidation_0-rmse:7.79681\n",
      "[34]\tvalidation_0-rmse:7.58082\n",
      "[35]\tvalidation_0-rmse:7.39390\n",
      "[36]\tvalidation_0-rmse:7.22556\n",
      "[37]\tvalidation_0-rmse:7.08235\n",
      "[38]\tvalidation_0-rmse:6.95314\n",
      "[39]\tvalidation_0-rmse:6.84619\n",
      "[40]\tvalidation_0-rmse:6.74506\n",
      "[41]\tvalidation_0-rmse:6.66353\n",
      "[42]\tvalidation_0-rmse:6.57771\n",
      "[43]\tvalidation_0-rmse:6.49145\n",
      "[44]\tvalidation_0-rmse:6.42365\n",
      "[45]\tvalidation_0-rmse:6.39423\n",
      "[46]\tvalidation_0-rmse:6.36774\n",
      "[47]\tvalidation_0-rmse:6.33918\n",
      "[48]\tvalidation_0-rmse:6.31625\n",
      "[49]\tvalidation_0-rmse:6.30022\n",
      "[50]\tvalidation_0-rmse:6.27842\n",
      "[51]\tvalidation_0-rmse:6.26118\n",
      "[52]\tvalidation_0-rmse:6.24314\n",
      "[53]\tvalidation_0-rmse:6.22599\n",
      "[54]\tvalidation_0-rmse:6.21781\n",
      "[55]\tvalidation_0-rmse:6.20635\n",
      "[56]\tvalidation_0-rmse:6.19572\n",
      "[57]\tvalidation_0-rmse:6.18497\n",
      "[58]\tvalidation_0-rmse:6.17566\n",
      "[59]\tvalidation_0-rmse:6.16472\n",
      "[60]\tvalidation_0-rmse:6.14368\n",
      "[61]\tvalidation_0-rmse:6.13700\n",
      "[62]\tvalidation_0-rmse:6.12960\n",
      "[63]\tvalidation_0-rmse:6.12135\n",
      "[64]\tvalidation_0-rmse:6.11558\n",
      "[65]\tvalidation_0-rmse:6.11069\n",
      "[66]\tvalidation_0-rmse:6.10727\n",
      "[67]\tvalidation_0-rmse:6.10277\n",
      "[68]\tvalidation_0-rmse:6.09823\n",
      "[69]\tvalidation_0-rmse:6.10304\n",
      "[70]\tvalidation_0-rmse:6.10724\n",
      "[71]\tvalidation_0-rmse:6.10717\n",
      "[72]\tvalidation_0-rmse:6.10937\n",
      "[73]\tvalidation_0-rmse:6.10900\n",
      "[74]\tvalidation_0-rmse:6.11095\n",
      "[75]\tvalidation_0-rmse:6.11275\n",
      "[76]\tvalidation_0-rmse:6.11311\n",
      "[77]\tvalidation_0-rmse:6.11242\n",
      "[78]\tvalidation_0-rmse:6.11170\n",
      "[79]\tvalidation_0-rmse:6.11158\n",
      "[80]\tvalidation_0-rmse:6.10949\n",
      "[81]\tvalidation_0-rmse:6.10931\n",
      "[82]\tvalidation_0-rmse:6.10870\n",
      "[83]\tvalidation_0-rmse:6.10827\n",
      "[84]\tvalidation_0-rmse:6.10615\n",
      "[85]\tvalidation_0-rmse:6.10497\n",
      "[86]\tvalidation_0-rmse:6.10457\n",
      "[87]\tvalidation_0-rmse:6.10547\n",
      "[88]\tvalidation_0-rmse:6.10426\n",
      "[89]\tvalidation_0-rmse:6.10530\n",
      "[90]\tvalidation_0-rmse:6.10444\n",
      "[91]\tvalidation_0-rmse:6.10510\n",
      "[92]\tvalidation_0-rmse:6.10537\n",
      "[93]\tvalidation_0-rmse:6.10566\n",
      "[94]\tvalidation_0-rmse:6.10615\n",
      "[95]\tvalidation_0-rmse:6.10560\n",
      "[96]\tvalidation_0-rmse:6.10490\n",
      "[97]\tvalidation_0-rmse:6.10404\n",
      "[98]\tvalidation_0-rmse:6.10322\n",
      "[99]\tvalidation_0-rmse:6.10249\n",
      "2025-09-05 15:56:27 - include.utilities.mlflow_utils - [INFO] - Successfully saved xgboost model as artifact\n",
      "2025-09-05 15:56:27 - include.ml.trainer - [INFO] - Top XGBoost features:\n",
      "[{'feature': 'profit', 'importance': 0.4588032066822052}, {'feature': 'sales_rolling_3_std', 'importance': 0.27154263854026794}, {'feature': 'quantity_sold', 'importance': 0.22969664633274078}, {'feature': 'day_sin', 'importance': 0.015169339254498482}, {'feature': 'sales_lag_7', 'importance': 0.011887287721037865}, {'feature': 'sales_rolling_3_max', 'importance': 0.004926057066768408}, {'feature': 'sales_rolling_3_min', 'importance': 0.0017841573571786284}, {'feature': 'store_id', 'importance': 0.001351720537059009}, {'feature': 'sales_rolling_3_mean', 'importance': 0.0010907917749136686}, {'feature': 'sales_lag_21', 'importance': 0.0009651501895859838}, {'feature': 'sales_rolling_14_mean', 'importance': 0.0009429207420907915}, {'feature': 'sales_lag_1', 'importance': 0.0005753137520514429}, {'feature': 'sales_rolling_7_std', 'importance': 0.0003677471249829978}, {'feature': 'sales_rolling_14_std', 'importance': 0.00024364472483284771}, {'feature': 'sales_lag_2', 'importance': 0.00017761514754965901}, {'feature': 'sales_lag_3', 'importance': 0.00017096697411034256}, {'feature': 'sales_rolling_7_mean', 'importance': 0.00011109308252343908}, {'feature': 'sales_rolling_30_std', 'importance': 4.192967389826663e-05}, {'feature': 'sales_rolling_7_min', 'importance': 3.383824150660075e-05}, {'feature': 'sales_rolling_14_max', 'importance': 2.8693551939795725e-05}]\n",
      "2025-09-05 15:56:28 - include.ml.trainer - [INFO] - Training LightGBM model\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 413\n",
      "[LightGBM] [Info] Number of data points in the train set: 60, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 89.312620\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tvalid_0's l2: 1647.57\n",
      "2025-09-05 15:56:28 - include.utilities.mlflow_utils - [INFO] - Successfully saved lightgbm model as artifact\n",
      "2025-09-05 15:56:28 - include.ml.trainer - [INFO] - Top LightGBM features:\n",
      "[{'feature': 'profit', 'importance': 35}, {'feature': 'day_cos', 'importance': 20}, {'feature': 'sales_rolling_7_mean', 'importance': 12}, {'feature': 'sales_lag_2', 'importance': 11}, {'feature': 'sales_rolling_3_std', 'importance': 11}, {'feature': 'quantity_sold', 'importance': 10}, {'feature': 'sales_rolling_21_std', 'importance': 9}, {'feature': 'sales_rolling_3_max', 'importance': 6}, {'feature': 'sales_rolling_7_std', 'importance': 6}, {'feature': 'sales_rolling_21_mean', 'importance': 4}, {'feature': 'sales_rolling_30_std', 'importance': 4}, {'feature': 'day_of_week_cos', 'importance': 4}, {'feature': 'sales_rolling_14_mean', 'importance': 3}, {'feature': 'sales_lag_1', 'importance': 1}, {'feature': 'store_id', 'importance': 0}, {'feature': 'has_promotion', 'importance': 0}, {'feature': 'customer_traffic', 'importance': 0}, {'feature': 'is_holiday', 'importance': 0}, {'feature': 'sales_lag_3', 'importance': 0}, {'feature': 'sales_lag_7', 'importance': 0}]\n",
      "2025-09-05 15:56:29 - include.ml.trainer - [INFO] - Ensemble weights - XGBoost: 0.602, LightGBM: 0.398\n",
      "2025-09-05 15:56:30 - include.utilities.mlflow_utils - [INFO] - Successfully saved ensemble model as artifact\n",
      "2025-09-05 15:56:30 - include.ml.trainer - [INFO] - Running model diagnostics...\n",
      "2025-09-05 15:56:30 - include.ml.diagnostics - [INFO] - Checking data quality...\n",
      "2025-09-05 15:56:30 - include.ml.diagnostics - [INFO] - Checking for distribution shift...\n",
      "2025-09-05 15:56:30 - include.ml.diagnostics - [INFO] - Analyzing predictions...\n",
      "2025-09-05 15:56:30 - include.ml.trainer - [INFO] - Diagnostic recommendations:\n",
      "2025-09-05 15:56:30 - include.ml.trainer - [WARNING] - - Potential data leakage: 1 features have >95% correlation with target\n",
      "2025-09-05 15:56:30 - include.ml.trainer - [WARNING] - - Small training set (60 samples). Consider generating more data.\n",
      "2025-09-05 15:56:30 - include.ml.trainer - [INFO] - Generating model comparison visualizations...\n",
      "2025-09-05 15:56:30 - include.ml.trainer - [INFO] - Starting visualization generation...\n",
      "2025-09-05 15:56:30 - include.ml.trainer - [INFO] - Creating visualizations in temporary directory: /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8\n",
      "2025-09-05 15:56:30 - include.ml.visualization - [INFO] - Saved metrics comparison chart to /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/metrics_comparison.png\n",
      "2025-09-05 15:56:31 - include.ml.visualization - [INFO] - Saved predictions comparison chart to /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/predictions_comparison.png\n",
      "2025-09-05 15:56:31 - include.ml.visualization - [INFO] - Residuals merge for xgboost: merged_shape=(38, 3), residuals_len=38, residuals_na=0\n",
      "2025-09-05 15:56:31 - include.ml.visualization - [INFO] - Residuals merge for lightgbm: merged_shape=(38, 3), residuals_len=38, residuals_na=0\n",
      "2025-09-05 15:56:31 - include.ml.visualization - [INFO] - Residuals merge for ensemble: merged_shape=(38, 3), residuals_len=38, residuals_na=0\n",
      "2025-09-05 15:56:31 - include.ml.visualization - [INFO] - Valid residuals keys: {'xgboost': 38, 'lightgbm': 38, 'ensemble': 38}\n",
      "2025-09-05 15:56:31 - include.ml.visualization - [INFO] - Saved residuals analysis chart to /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/residuals_analysis.png\n",
      "2025-09-05 15:56:31 - include.ml.visualization - [INFO] - Saved error distribution chart to /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/error_distribution.png\n",
      "2025-09-05 15:56:32 - include.ml.visualization - [INFO] - Saved feature importance chart to /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/feature_importance.png\n",
      "2025-09-05 15:56:32 - include.ml.visualization - [INFO] - Generated 6 visualization files in /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8\n",
      "2025-09-05 15:56:32 - include.ml.trainer - [INFO] - Generated 6 visualization files: ['metrics_comparison', 'predictions_comparison', 'residuals_analysis', 'error_distribution', 'feature_importance', 'summary']\n",
      "2025-09-05 15:56:32 - include.ml.trainer - [INFO] - Logged visualization: metrics_comparison from /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/metrics_comparison.png\n",
      "2025-09-05 15:56:32 - include.ml.trainer - [INFO] - Logged visualization: predictions_comparison from /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/predictions_comparison.png\n",
      "2025-09-05 15:56:32 - include.ml.trainer - [INFO] - Logged visualization: residuals_analysis from /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/residuals_analysis.png\n",
      "2025-09-05 15:56:32 - include.ml.trainer - [INFO] - Logged visualization: error_distribution from /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/error_distribution.png\n",
      "2025-09-05 15:56:32 - include.ml.trainer - [INFO] - Logged visualization: feature_importance from /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/feature_importance.png\n",
      "2025-09-05 15:56:32 - include.ml.trainer - [INFO] - Logged visualization: summary from /var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpyqyazjs8/model_comparison_summary.png\n",
      "2025-09-05 15:56:32 - include.ml.trainer - [INFO] - Logged combined HTML report\n",
      "2025-09-05 15:56:32 - include.ml.trainer - [INFO] - Artifacts saved successfully\n",
      "🏃 View run sales_forecasting_training_2025-09-05T15:56:26 at: http://localhost:5001/#/experiments/1/runs/ba4fdb57e96742fa8000536ea248c5aa\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/1\n",
      "2025-09-05 15:56:32 - include.utilities.mlflow_utils - [INFO] - Ended MLflow run\n",
      "WARNING: No regex match found!\n",
      "2025-09-05 15:56:32 - include.utilities.mlflow_s3_utils - [INFO] - Synced encoders.pkl to S3\n",
      "2025-09-05 15:56:32 - include.utilities.mlflow_s3_utils - [INFO] - Synced feature_cols.pkl to S3\n",
      "2025-09-05 15:56:32 - include.utilities.mlflow_s3_utils - [INFO] - Synced scalers.pkl to S3\n",
      "2025-09-05 15:56:32 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/ensemble/ensemble_model.pkl to S3\n",
      "2025-09-05 15:56:32 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/ensemble/ensemble_metadata.yaml to S3\n",
      "2025-09-05 15:56:32 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/xgboost/xgboost_metadata.yaml to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/xgboost/xgboost_model.pkl to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/lightgbm/lightgbm_metadata.yaml to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/lightgbm/lightgbm_model.pkl to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/predictions_comparison.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/error_distribution.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/residuals_analysis.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/feature_importance.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/model_comparison_summary.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/metrics_comparison.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced reports/model_comparison_report.html to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Successfully synced all artifacts for run ba4fdb57e96742fa8000536ea248c5aa to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_utils - [INFO] - Synced artifacts to S3 for run ba4fdb57e96742fa8000536ea248c5aa\n",
      "2025-09-05 15:56:33 - include.ml.trainer - [INFO] - Syncing artifacts to S3...\n",
      "WARNING: No regex match found!\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced encoders.pkl to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced feature_cols.pkl to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced scalers.pkl to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/ensemble/ensemble_model.pkl to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/ensemble/ensemble_metadata.yaml to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/xgboost/xgboost_metadata.yaml to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/xgboost/xgboost_model.pkl to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/lightgbm/lightgbm_metadata.yaml to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced models/lightgbm/lightgbm_model.pkl to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/predictions_comparison.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/error_distribution.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/residuals_analysis.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/feature_importance.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/model_comparison_summary.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced visualizations/metrics_comparison.png to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Synced reports/model_comparison_report.html to S3\n",
      "2025-09-05 15:56:33 - include.utilities.mlflow_s3_utils - [INFO] - Successfully synced all artifacts for run ba4fdb57e96742fa8000536ea248c5aa to S3\n",
      "2025-09-05 15:56:33 - include.ml.trainer - [INFO] - ✅ Successfully synced artifacts to S3\n",
      "2025-09-05 15:56:33 - include.ml.trainer - [INFO] - Verifying S3 artifact storage...\n",
      "WARNING: No regex match found!\n",
      "2025-09-05 15:56:33 - include.utilities.s3_verification - [INFO] - Found 16 artifacts in S3 for run ba4fdb57e96742fa8000536ea248c5aa\n",
      "2025-09-05 15:56:33 - include.utilities.s3_verification - [INFO] - Artifacts: encoders.pkl, feature_cols.pkl, models/ensemble/ensemble_metadata.yaml, models/ensemble/ensemble_model.pkl, models/lightgbm/lightgbm_metadata.yaml...\n",
      "2025-09-05 15:56:33 - include.utilities.s3_verification - [INFO] - ✓ S3 artifact verification PASSED\n",
      "2025-09-05 15:56:33 - include.utilities.s3_verification - [INFO] -   - Artifact URI: s3://mlflow-artifacts/1/ba4fdb57e96742fa8000536ea248c5aa/artifacts\n",
      "2025-09-05 15:56:33 - include.utilities.s3_verification - [INFO] -   - Total artifacts: 16\n",
      "\n",
      "xgboost metrics:\n",
      "  rmse: 18.3796\n",
      "  mae: 10.7894\n",
      "  mape: 10.6073\n",
      "  r2: 0.9145\n",
      "\n",
      "lightgbm metrics:\n",
      "  rmse: 37.1117\n",
      "  mae: 24.4866\n",
      "  mape: 28.2762\n",
      "  r2: 0.6516\n",
      "\n",
      "ensemble metrics:\n",
      "  rmse: 24.3990\n",
      "  mae: 15.1426\n",
      "  mape: 15.8903\n",
      "  r2: 0.8494\n",
      "\n",
      "Visualization charts have been generated and saved to MLflow/MinIO\n",
      "Charts include:\n",
      "  - Model metrics comparison\n",
      "  - Predictions vs actual values\n",
      "  - Residuals analysis\n",
      "  - Error distribution\n",
      "  - Feature importance comparison\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'training_results'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'xgboost'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'rmse'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.float64</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.379562127055145</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">)</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'mae'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.789397564439817</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'mape'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.float64</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.607308696772018</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">)</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'r2'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9145493550051114</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">            </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'lightgbm'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'rmse'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.float64</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37.11168982251988</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">)</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'mae'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.486613680711407</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'mape'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.float64</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28.27618638037453</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">)</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'r2'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6516093560747661</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">            </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #008000; text-decoration-color: #008000\">'ensemble'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'metrics'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">{</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'rmse'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.float64</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24.39904443776479</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">)</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'mae'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.14255268659498</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'mape'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">np.float64</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.890263737263504</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">)</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">                </span><span style=\"color: #008000; text-decoration-color: #008000\">'r2'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.849411897824528</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">            </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">        </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">,</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00\">    </span><span style=\"color: #008000; text-decoration-color: #008000\">'mlflow_run_id'</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'run_2025-09-05T15:56:33'</span>\n",
       "<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m    \u001b[0m\u001b[32m'training_results'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'xgboost'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m            \u001b[0m\u001b[32m'metrics'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'rmse'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;35mnp.float64\u001b[0m\u001b[1;38;2;0;255;0m(\u001b[0m\u001b[1;36m18.379562127055145\u001b[0m\u001b[1;38;2;0;255;0m)\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'mae'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m10.789397564439817\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'mape'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;35mnp.float64\u001b[0m\u001b[1;38;2;0;255;0m(\u001b[0m\u001b[1;36m10.607308696772018\u001b[0m\u001b[1;38;2;0;255;0m)\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'r2'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m0.9145493550051114\u001b[0m\n",
       "\u001b[38;2;0;255;0m            \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'lightgbm'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m            \u001b[0m\u001b[32m'metrics'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'rmse'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;35mnp.float64\u001b[0m\u001b[1;38;2;0;255;0m(\u001b[0m\u001b[1;36m37.11168982251988\u001b[0m\u001b[1;38;2;0;255;0m)\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'mae'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m24.486613680711407\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'mape'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;35mnp.float64\u001b[0m\u001b[1;38;2;0;255;0m(\u001b[0m\u001b[1;36m28.27618638037453\u001b[0m\u001b[1;38;2;0;255;0m)\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'r2'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m0.6516093560747661\u001b[0m\n",
       "\u001b[38;2;0;255;0m            \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[32m'ensemble'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m            \u001b[0m\u001b[32m'metrics'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;38;2;0;255;0m{\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'rmse'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;35mnp.float64\u001b[0m\u001b[1;38;2;0;255;0m(\u001b[0m\u001b[1;36m24.39904443776479\u001b[0m\u001b[1;38;2;0;255;0m)\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'mae'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m15.14255268659498\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'mape'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;35mnp.float64\u001b[0m\u001b[1;38;2;0;255;0m(\u001b[0m\u001b[1;36m15.890263737263504\u001b[0m\u001b[1;38;2;0;255;0m)\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m                \u001b[0m\u001b[32m'r2'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[1;36m0.849411897824528\u001b[0m\n",
       "\u001b[38;2;0;255;0m            \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\n",
       "\u001b[38;2;0;255;0m        \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\n",
       "\u001b[38;2;0;255;0m    \u001b[0m\u001b[1;38;2;0;255;0m}\u001b[0m\u001b[38;2;0;255;0m,\u001b[0m\n",
       "\u001b[38;2;0;255;0m    \u001b[0m\u001b[32m'mlflow_run_id'\u001b[0m\u001b[38;2;0;255;0m: \u001b[0m\u001b[32m'run_2025-09-05T15:56:33'\u001b[0m\n",
       "\u001b[1;38;2;0;255;0m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.end_run()\n",
    "\n",
    "results = trainer.train_all_models(train_df, val_df, test_df, target_col=\"sales\")\n",
    "for model_name, model_results in results.items():\n",
    "    if \"metrics\" in model_results:\n",
    "        print(f\"\\n{model_name} metrics:\")\n",
    "        for metric, value in model_results[\"metrics\"].items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "print(\"\\nVisualization charts have been generated and saved to MLflow/MinIO\")\n",
    "print(\"Charts include:\")\n",
    "print(\"  - Model metrics comparison\")\n",
    "print(\"  - Predictions vs actual values\")\n",
    "print(\"  - Residuals analysis\")\n",
    "print(\"  - Error distribution\")\n",
    "print(\"  - Feature importance comparison\")\n",
    "\n",
    "serializable_results: dict[str, dict[str, Any]] = {}\n",
    "for model_name, model_results in results.items():\n",
    "    serializable_results[model_name] = {\"metrics\": model_results.get(\"metrics\", {})}\n",
    "\n",
    "serializable_results: dict[str, dict[str, Any]] = {}\n",
    "for model_name, model_results in results.items():\n",
    "    serializable_results[model_name] = {\"metrics\": model_results.get(\"metrics\", {})}\n",
    "\n",
    "\n",
    "current_run = trainer.mlflow_manager.get_run_id()\n",
    "final_results: dict[str, Any] = {\n",
    "    \"training_results\": serializable_results,\n",
    "    \"mlflow_run_id\": current_run,\n",
    "}\n",
    "console.print(final_results, style=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2490c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cdd3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623d1bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d2d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122004e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0851577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ed365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pl.DataFrame = pl.DataFrame(\n",
    "    data={\n",
    "        \"id\": [1, 2, 3, 4],\n",
    "        \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Bob\"],\n",
    "        \"role\": [\"Engineer\", \"Manager\", \"Engineer\", \"Manager\"],\n",
    "        \"skill\": [\"Python\", \"Leadership\", \"Python\", \"Management\"],\n",
    "        \"experience\": [5, 2, 3, 3],\n",
    "        \"age\": [30, 40, 35, 34],\n",
    "        \"target\": [1, 0, 1, 1],\n",
    "    }\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f87382",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df[\"name\"].value_counts()\n",
    "mean_target = df.group_by(\"name\").agg(pl.col(\"target\").mean())\n",
    "display(mean_target)\n",
    "display(counts[\"name\"])\n",
    "for row in counts[\"name\"]:\n",
    "    print(counts.filter(pl.col(\"name\").eq(row))[\"count\"].item())\n",
    "\n",
    "counts.filter(pl.col(\"name\").eq(\"Alice\"))[\"count\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bac96a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f527771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d70434e",
   "metadata": {},
   "source": [
    "### Connect To MLFlow\n",
    "\n",
    "- Set the `tracking URI` to the MLflow server.\n",
    "    - Tracking URI requires the MLflow `server address`, `port`, `S3 endpoint URL`, and `S3 credentials`.\n",
    "    - S3 credentials include `access key`, `secret key`, and `bucket name`.\n",
    "    - `MinIO` is used as a local S3-compatible storage service.\n",
    "\n",
    "- Verify the connection by listing experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf35299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force localhost configuration and debug\n",
    "RUNNING_IN_DOCKER = False\n",
    "DEFAULT_MINIO_HOST = app_settings.AWS_S3_HOST if RUNNING_IN_DOCKER else \"minio\"\n",
    "DEFAULT_MINIO_PORT = app_settings.AWS_S3_PORT\n",
    "MINIO_ENDPOINT = app_settings.mlflow_s3_endpoint_url\n",
    "# This connects to the MLflow server with PostgreSQL backend\n",
    "MLFLOW_URI = app_settings.mlflow_tracking_uri\n",
    "AWS_KEY = app_settings.AWS_ACCESS_KEY_ID\n",
    "AWS_SECRET = app_settings.AWS_SECRET_ACCESS_KEY.get_secret_value()\n",
    "AWS_REGION = app_settings.AWS_DEFAULT_REGION\n",
    "BUCKET = app_settings.AWS_S3_BUCKET\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = app_settings.AWS_ACCESS_KEY_ID\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = AWS_REGION\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = MINIO_ENDPOINT\n",
    "\n",
    "print(\"=== CONFIGURATION DEBUG ===\")\n",
    "print(f\"RUNNING_IN_DOCKER: {RUNNING_IN_DOCKER}\")\n",
    "print(f\"DEFAULT_MINIO_HOST: {DEFAULT_MINIO_HOST}\")\n",
    "print(f\"MINIO_ENDPOINT: {MINIO_ENDPOINT}\")\n",
    "print(f\"MLFLOW_URI: {MLFLOW_URI}\")\n",
    "print(f\"AWS_ACCESS_KEY_ID: {AWS_KEY}\")\n",
    "print(f\"BUCKET: {BUCKET}\")\n",
    "print(f\"Environment MLFLOW_S3_ENDPOINT_URL: {MINIO_ENDPOINT}\")\n",
    "print(\"=== END CONFIGURATION DEBUG ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b689ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MLflow server connection and S3 storage\n",
    "import tempfile\n",
    "import traceback\n",
    "\n",
    "import boto3\n",
    "import mlflow\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# 1) Test S3/MinIO connection\n",
    "print(\"Testing S3/MinIO connection...\")\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    aws_access_key_id=AWS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET,\n",
    "    region_name=AWS_REGION,\n",
    ")\n",
    "\n",
    "try:\n",
    "    s3.head_bucket(Bucket=BUCKET)\n",
    "    print(f\"✅ Bucket '{BUCKET}' is reachable\")\n",
    "except ClientError as e:\n",
    "    print(f\"❌ S3/MinIO connection failed: {e}\")\n",
    "\n",
    "# 2) Test MLflow server connection\n",
    "print(f\"\\nTesting MLflow server connection to {MLFLOW_URI}...\")\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "print(f\"✅ MLflow tracking URI set to: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# 3) Test that MLflow uses PostgreSQL backend (not local files)\n",
    "try:\n",
    "    # This should connect to the MLflow server which uses PostgreSQL\n",
    "    experiments = mlflow.search_experiments()\n",
    "    print(f\"✅ Connected to MLflow server. Found {len(experiments)} experiments.\")\n",
    "    print(\"✅ This confirms MLflow is using the PostgreSQL backend, not local files.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to connect to MLflow server: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"IMPORTANT: If MLflow server is using PostgreSQL correctly,\")\n",
    "print(\"experiments and runs will be stored in the database,\")\n",
    "print(\"and artifacts will be stored in MinIO/S3.\")\n",
    "print(\"Local 'mlruns' folders should NOT be created.\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc2832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from botocore.exceptions import ClientError\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "try:\n",
    "    mlflow.set_experiment(\"notebook_quick_test\")\n",
    "    X, y = datasets.load_diabetes(return_X_y=True)\n",
    "    model = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.log_param(\"alpha\", 0.1)\n",
    "        mlflow.log_param(\"l1_ratio\", 0.5)\n",
    "        mlflow.log_metric(\"dummy_score\", model.score(X, y))\n",
    "\n",
    "        # Create a small artifact file and upload\n",
    "        with tempfile.NamedTemporaryFile(\"w\", suffix=\".txt\", delete=False) as tmp:\n",
    "            tmp.write(\"mlflow artifact test\")\n",
    "            tmp_path = tmp.name\n",
    "\n",
    "        mlflow.log_artifact(tmp_path, artifact_path=\"test_artifacts\")\n",
    "        mlflow.sklearn.log_model(model, \"model\", input_example=X[:2].tolist())\n",
    "\n",
    "        # Remove temp file after logging\n",
    "        os.remove(tmp_path)\n",
    "\n",
    "        print(\"✅ Logged run id:\", run.info.run_id)\n",
    "        print(\"✅ Experiment id:\", run.info.experiment_id)\n",
    "\n",
    "    print(\"✅ MLflow logging complete — check the UI and MinIO for artifact/model.\")\n",
    "    print(\"✅ Data stored in PostgreSQL database, artifacts in MinIO S3\")\n",
    "\n",
    "except ClientError as e:\n",
    "    # boto3 ClientError can surface during artifact upload\n",
    "    print(\"❌ Boto3 ClientError during MLflow operations:\", e)\n",
    "    print(traceback.format_exc())\n",
    "    raise\n",
    "except Exception:\n",
    "    print(\"❌ Unexpected error during MLflow logging:\")\n",
    "    print(traceback.format_exc())\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9ea91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93578dee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca7341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eceaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ded3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cyclical_features(df: pl.DataFrame, date_col: str = \"date\") -> pl.DataFrame:\n",
    "    df = df.clone()\n",
    "\n",
    "    return df.with_columns(\n",
    "        # month (convert 1-12 to 0-11 for proper cyclical encoding)\n",
    "        pl.col(date_col).dt.month().map_elements(lambda x: np.sin(2 * np.pi * (x - 1) / 12)).alias(\"month_sin\"),\n",
    "        pl.col(date_col).dt.month().map_elements(lambda x: np.cos(2 * np.pi * (x - 1) / 12)).alias(\"month_cos\"),\n",
    "        # day (Retain original values; 1-31)\n",
    "        pl.col(date_col).dt.day().map_elements(lambda x: np.sin(2 * np.pi * x / 31)).alias(\"day_sin\"),\n",
    "        pl.col(date_col).dt.day().map_elements(lambda x: np.cos(2 * np.pi * x / 31)).alias(\"day_cos\"),\n",
    "        # day of week (convert 1-7 to 0-6 for proper cyclical encoding)\n",
    "        pl.col(date_col).dt.weekday().map_elements(lambda x: np.sin(2 * np.pi * (x - 1) / 7)).alias(\"day_of_week_sin\"),\n",
    "        pl.col(date_col).dt.weekday().map_elements(lambda x: np.cos(2 * np.pi * (x - 1) / 7)).alias(\"day_of_week_cos\"),\n",
    "    )\n",
    "\n",
    "\n",
    "create_cyclical_features(temp_df, date_col=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10909e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Any, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import plotly.io as pio\n",
    "\n",
    "# Set default template\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "\n",
    "class PlotlyModelVisualizer:\n",
    "    \"\"\"Create comprehensive visualizations for model comparison and analysis using Plotly\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize the visualizer with color scheme\"\"\"\n",
    "        self.colors = {\n",
    "            \"xgboost\": \"#FF6B6B\",\n",
    "            \"lightgbm\": \"#A7D7D4\", \n",
    "            \"prophet\": \"#99D145\",\n",
    "            \"ensemble\": \"#198050\",\n",
    "            \"actual\": \"#17222E\",\n",
    "        }\n",
    "\n",
    "    def create_performance_dashboard(\n",
    "        self, metrics_dict: Dict[str, Dict[str, float]], save_path: Optional[str] = None\n",
    "    ) -> go.Figure:\n",
    "        \"\"\"Create a comprehensive performance dashboard combining metrics and rankings.\"\"\"\n",
    "        \n",
    "        models = list(metrics_dict.keys())\n",
    "        \n",
    "        # Create subplot structure\n",
    "        fig = make_subplots(\n",
    "            rows=3, cols=3,\n",
    "            subplot_titles=[\n",
    "                \"RMSE\", \"MAE\", \"MAPE (%)\", \"R² Score\", \n",
    "                \"Overall Model Ranking\", \"Normalized Performance\"\n",
    "            ],\n",
    "            specs=[\n",
    "                [{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "                [{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}], \n",
    "                [{\"colspan\": 3, \"type\": \"bar\"}, None, None]\n",
    "            ],\n",
    "            vertical_spacing=0.12,\n",
    "            horizontal_spacing=0.08\n",
    "        )\n",
    "\n",
    "        # Individual metric plots\n",
    "        metrics_info = [\n",
    "            (\"rmse\", \"RMSE\", True, 1, 1),\n",
    "            (\"mae\", \"MAE\", True, 1, 2), \n",
    "            (\"mape\", \"MAPE (%)\", True, 1, 3),\n",
    "            (\"r2\", \"R² Score\", False, 2, 1),\n",
    "        ]\n",
    "\n",
    "        for metric, title, lower_better, row, col in metrics_info:\n",
    "            values = [metrics_dict[model].get(metric, 0) for model in models]\n",
    "            colors = [self.colors.get(model.lower(), \"#95A5A6\") for model in models]\n",
    "            \n",
    "            # Highlight best model\n",
    "            best_idx = values.index(min(values) if lower_better else max(values))\n",
    "            edge_colors = ['green' if i == best_idx else 'rgba(0,0,0,0)' for i in range(len(models))]\n",
    "            edge_widths = [3 if i == best_idx else 0 for i in range(len(models))]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=models,\n",
    "                    y=values,\n",
    "                    marker=dict(\n",
    "                        color=colors,\n",
    "                        line=dict(color=edge_colors, width=edge_widths)\n",
    "                    ),\n",
    "                    text=[f\"{v:.3f}\" for v in values],\n",
    "                    textposition=\"outside\",\n",
    "                    showlegend=False,\n",
    "                    name=title\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "        # Model ranking (top right)\n",
    "        ranking_data = self._calculate_model_ranking(metrics_dict)\n",
    "        models_sorted = [x[0] for x in ranking_data]\n",
    "        scores_sorted = [x[1] for x in ranking_data]\n",
    "        colors_sorted = [self.colors.get(model.lower(), \"#95A5A6\") for model in models_sorted]\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                y=models_sorted,\n",
    "                x=scores_sorted,\n",
    "                orientation='h',\n",
    "                marker=dict(color=colors_sorted),\n",
    "                text=[f\"{score:.2f}\" for score in scores_sorted],\n",
    "                textposition=\"outside\",\n",
    "                showlegend=False,\n",
    "                name=\"Model Ranking\"\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "\n",
    "        # Normalized performance comparison (bottom)\n",
    "        norm_data = self._calculate_normalized_performance(metrics_dict)\n",
    "        \n",
    "        # Create grouped bar chart for normalized performance\n",
    "        metrics = [\"rmse\", \"mae\", \"mape\", \"r2\"]\n",
    "        colors_metrics = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\"]\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=models,\n",
    "                    y=norm_data[metric],\n",
    "                    name=metric.upper(),\n",
    "                    marker=dict(color=colors_metrics[i]),\n",
    "                    text=[f\"{v:.2f}\" for v in norm_data[metric]],\n",
    "                    textposition=\"outside\",\n",
    "                    offsetgroup=i,\n",
    "                    showlegend=True\n",
    "                ),\n",
    "                row=3, col=1\n",
    "            )\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=900,\n",
    "            title_text=\"Model Performance Dashboard\",\n",
    "            title_x=0.5,\n",
    "            title_font_size=18,\n",
    "            showlegend=True,\n",
    "            legend=dict(x=0.7, y=0.3)\n",
    "        )\n",
    "        \n",
    "        # Update axes\n",
    "        fig.update_xaxes(title_text=\"Models\", row=3, col=1)\n",
    "        fig.update_yaxes(title_text=\"Normalized Performance\", row=3, col=1)\n",
    "        fig.update_xaxes(title_text=\"Average Rank\", row=2, col=2)\n",
    "        fig.update_yaxes(title_text=\"Models\", row=2, col=2)\n",
    "\n",
    "        if save_path:\n",
    "            fig.write_html(save_path)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def create_prediction_quality_analysis(\n",
    "        self,\n",
    "        predictions_dict: Dict[str, Union[pd.DataFrame, pl.DataFrame]],\n",
    "        actual_data: Union[pd.DataFrame, pl.DataFrame],\n",
    "        date_col: str = \"date\",\n",
    "        target_col: str = \"sales\",\n",
    "        save_path: Optional[str] = None,\n",
    "    ) -> go.Figure:\n",
    "        \"\"\"Create prediction quality analysis combining scatter plots and time series.\"\"\"\n",
    "        \n",
    "        # Convert to pandas if needed\n",
    "        if isinstance(actual_data, pl.DataFrame):\n",
    "            actual_data = actual_data.to_pandas()\n",
    "\n",
    "        predictions_dict = {\n",
    "            k: (v.to_pandas() if isinstance(v, pl.DataFrame) else v) \n",
    "            for k, v in predictions_dict.items()\n",
    "        }\n",
    "\n",
    "        n_models = len(predictions_dict)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=n_models,\n",
    "            subplot_titles=[f\"{model} - Actual vs Predicted\" for model in predictions_dict.keys()] +\n",
    "                          [f\"{model} - Time Series\" for model in predictions_dict.keys()],\n",
    "            vertical_spacing=0.12\n",
    "        )\n",
    "\n",
    "        for idx, (model_name, pred_df) in enumerate(predictions_dict.items()):\n",
    "            col = idx + 1\n",
    "            \n",
    "            # Merge data\n",
    "            merged = pd.merge(\n",
    "                actual_data[[date_col, target_col]], \n",
    "                pred_df[[date_col, \"prediction\"]], \n",
    "                on=date_col, how=\"inner\"\n",
    "            )\n",
    "\n",
    "            color = self.colors.get(model_name.lower(), \"#95A5A6\")\n",
    "\n",
    "            # Top row: Actual vs Predicted scatter\n",
    "            min_val = min(merged[target_col].min(), merged[\"prediction\"].min())\n",
    "            max_val = max(merged[target_col].max(), merged[\"prediction\"].max())\n",
    "            \n",
    "            # Scatter plot\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=merged[target_col],\n",
    "                    y=merged[\"prediction\"],\n",
    "                    mode='markers',\n",
    "                    marker=dict(color=color, opacity=0.6, size=4),\n",
    "                    showlegend=False,\n",
    "                    name=f\"{model_name} Predictions\"\n",
    "                ),\n",
    "                row=1, col=col\n",
    "            )\n",
    "            \n",
    "            # Perfect prediction line\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[min_val, max_val],\n",
    "                    y=[min_val, max_val],\n",
    "                    mode='lines',\n",
    "                    line=dict(color='red', dash='dash'),\n",
    "                    showlegend=False,\n",
    "                    name=\"Perfect Prediction\"\n",
    "                ),\n",
    "                row=1, col=col\n",
    "            )\n",
    "\n",
    "            # Calculate R²\n",
    "            r2 = r2_score(merged[target_col], merged[\"prediction\"])\n",
    "            \n",
    "            # Add R² annotation\n",
    "            fig.add_annotation(\n",
    "                x=0.05, y=0.95,\n",
    "                text=f\"R² = {r2:.3f}\",\n",
    "                showarrow=False,\n",
    "                xref=f\"x{col if col > 1 else ''} domain\",\n",
    "                yref=f\"y{col if col > 1 else ''} domain\",\n",
    "                bgcolor=\"white\",\n",
    "                bordercolor=\"black\",\n",
    "                row=1, col=col\n",
    "            )\n",
    "\n",
    "            # Bottom row: Time series comparison\n",
    "            if len(merged) > 500:\n",
    "                sample_idx = np.linspace(0, len(merged) - 1, 500, dtype=int)\n",
    "                plot_data = merged.iloc[sample_idx]\n",
    "            else:\n",
    "                plot_data = merged\n",
    "\n",
    "            # Actual values\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=plot_data[date_col],\n",
    "                    y=plot_data[target_col],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=self.colors[\"actual\"], width=2),\n",
    "                    name=\"Actual\" if col == 1 else None,\n",
    "                    showlegend=(col == 1),\n",
    "                    legendgroup=\"actual\"\n",
    "                ),\n",
    "                row=2, col=col\n",
    "            )\n",
    "            \n",
    "            # Predictions\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=plot_data[date_col],\n",
    "                    y=plot_data[\"prediction\"],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=color, width=2),\n",
    "                    name=f\"{model_name} Prediction\" if col == 1 else None,\n",
    "                    showlegend=(col == 1),\n",
    "                    legendgroup=model_name\n",
    "                ),\n",
    "                row=2, col=col\n",
    "            )\n",
    "\n",
    "            # Add confidence intervals if available\n",
    "            if \"prediction_lower\" in pred_df.columns and \"prediction_upper\" in pred_df.columns:\n",
    "                plot_data_conf = pd.merge(plot_data, pred_df[[date_col, \"prediction_lower\", \"prediction_upper\"]], on=date_col, how=\"left\")\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=plot_data_conf[date_col],\n",
    "                        y=plot_data_conf[\"prediction_upper\"],\n",
    "                        mode='lines',\n",
    "                        line=dict(width=0),\n",
    "                        showlegend=False,\n",
    "                        hoverinfo='skip'\n",
    "                    ),\n",
    "                    row=2, col=col\n",
    "                )\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=plot_data_conf[date_col],\n",
    "                        y=plot_data_conf[\"prediction_lower\"],\n",
    "                        mode='lines',\n",
    "                        line=dict(width=0),\n",
    "                        fill='tonexty',\n",
    "                        fillcolor=f'rgba{tuple(list(px.colors.hex_to_rgb(color)) + [0.2])}',\n",
    "                        showlegend=False,\n",
    "                        hoverinfo='skip'\n",
    "                    ),\n",
    "                    row=2, col=col\n",
    "                )\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=600,\n",
    "            title_text=\"Prediction Quality Analysis\",\n",
    "            title_x=0.5,\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        # Update axes labels\n",
    "        for col in range(1, n_models + 1):\n",
    "            fig.update_xaxes(title_text=f\"Actual {target_col.title()}\", row=1, col=col)\n",
    "            fig.update_yaxes(title_text=\"Predicted\", row=1, col=col)\n",
    "            fig.update_xaxes(title_text=\"Date\", row=2, col=col)\n",
    "            fig.update_yaxes(title_text=target_col.title(), row=2, col=col)\n",
    "\n",
    "        if save_path:\n",
    "            fig.write_html(save_path)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def create_residuals_diagnostic_panel(\n",
    "        self,\n",
    "        predictions_dict: Dict[str, Union[pd.DataFrame, pl.DataFrame]],\n",
    "        actual_data: Union[pd.DataFrame, pl.DataFrame],\n",
    "        target_col: str = \"sales\",\n",
    "        save_path: Optional[str] = None,\n",
    "    ) -> go.Figure:\n",
    "        \"\"\"Create comprehensive residuals diagnostic panel.\"\"\"\n",
    "        \n",
    "        if isinstance(actual_data, pl.DataFrame):\n",
    "            actual_data = actual_data.to_pandas()\n",
    "\n",
    "        predictions_dict = {\n",
    "            k: (v.to_pandas() if isinstance(v, pl.DataFrame) else v) \n",
    "            for k, v in predictions_dict.items()\n",
    "        }\n",
    "\n",
    "        # Calculate residuals\n",
    "        residuals_data = {}\n",
    "        for model_name, pred_df in predictions_dict.items():\n",
    "            merged = pd.merge(actual_data[[\"date\", target_col]], pred_df[[\"date\", \"prediction\"]], on=\"date\", how=\"inner\")\n",
    "            residuals = merged[target_col] - merged[\"prediction\"]\n",
    "            residuals_data[model_name] = {\n",
    "                \"residuals\": residuals,\n",
    "                \"predictions\": merged[\"prediction\"],\n",
    "                \"actual\": merged[target_col],\n",
    "                \"dates\": merged[\"date\"],\n",
    "            }\n",
    "\n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=3,\n",
    "            subplot_titles=[\n",
    "                \"Residuals Distribution\", \"Residuals vs Fitted Values\", \"Scale-Location Plot\",\n",
    "                \"Residuals Over Time\", \"Normal Q-Q Plot\", \"Residuals Distribution (Box)\"\n",
    "            ],\n",
    "            specs=[\n",
    "                [{\"type\": \"histogram\"}, {\"type\": \"scatter\"}, {\"type\": \"scatter\"}],\n",
    "                [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}, {\"type\": \"box\"}]\n",
    "            ],\n",
    "            vertical_spacing=0.12\n",
    "        )\n",
    "\n",
    "        # 1. Residuals distribution comparison\n",
    "        for model_name, data in residuals_data.items():\n",
    "            residuals = data[\"residuals\"].dropna()\n",
    "            if len(residuals) > 0:\n",
    "                fig.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x=residuals,\n",
    "                        nbinsx=30,\n",
    "                        opacity=0.6,\n",
    "                        name=model_name,\n",
    "                        marker=dict(color=self.colors.get(model_name.lower(), \"#95A5A6\")),\n",
    "                        histnorm='probability density',\n",
    "                        showlegend=True,\n",
    "                        legendgroup=model_name\n",
    "                    ),\n",
    "                    row=1, col=1\n",
    "                )\n",
    "\n",
    "        # Add vertical line at x=0\n",
    "        fig.add_vline(x=0, line_dash=\"dash\", line_color=\"red\", opacity=0.7, row=1, col=1)\n",
    "\n",
    "        # 2. Residuals vs Fitted\n",
    "        for model_name, data in residuals_data.items():\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=data[\"predictions\"],\n",
    "                    y=data[\"residuals\"],\n",
    "                    mode='markers',\n",
    "                    marker=dict(color=self.colors.get(model_name.lower(), \"#95A5A6\"), opacity=0.6, size=4),\n",
    "                    name=model_name,\n",
    "                    showlegend=False,\n",
    "                    legendgroup=model_name\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "\n",
    "        # Add horizontal line at y=0\n",
    "        fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\", opacity=0.7, row=1, col=2)\n",
    "\n",
    "        # 3. Scale-Location plot\n",
    "        for model_name, data in residuals_data.items():\n",
    "            residuals = data[\"residuals\"]\n",
    "            predictions = data[\"predictions\"]\n",
    "            std_residuals = np.sqrt(np.abs(residuals / residuals.std()))\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=predictions,\n",
    "                    y=std_residuals,\n",
    "                    mode='markers',\n",
    "                    marker=dict(color=self.colors.get(model_name.lower(), \"#95A5A6\"), opacity=0.6, size=4),\n",
    "                    name=model_name,\n",
    "                    showlegend=False,\n",
    "                    legendgroup=model_name\n",
    "                ),\n",
    "                row=1, col=3\n",
    "            )\n",
    "\n",
    "        # 4. Residuals over time\n",
    "        for model_name, data in residuals_data.items():\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=data[\"dates\"],\n",
    "                    y=data[\"residuals\"],\n",
    "                    mode='lines',\n",
    "                    line=dict(color=self.colors.get(model_name.lower(), \"#95A5A6\"), width=1),\n",
    "                    name=model_name,\n",
    "                    showlegend=False,\n",
    "                    legendgroup=model_name\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "\n",
    "        # Add horizontal line at y=0\n",
    "        fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\", opacity=0.7, row=2, col=1)\n",
    "\n",
    "        # 5. Q-Q Plot (Normal probability plot)\n",
    "        for model_name, data in residuals_data.items():\n",
    "            residuals = data[\"residuals\"].dropna().values\n",
    "            if len(residuals) > 0:\n",
    "                # Calculate Q-Q plot points\n",
    "                sorted_residuals = np.sort(residuals)\n",
    "                n = len(sorted_residuals)\n",
    "                theoretical_quantiles = stats.norm.ppf(np.arange(1, n + 1) / (n + 1))\n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=theoretical_quantiles,\n",
    "                        y=sorted_residuals,\n",
    "                        mode='markers',\n",
    "                        marker=dict(color=self.colors.get(model_name.lower(), \"#95A5A6\"), size=4),\n",
    "                        name=model_name,\n",
    "                        showlegend=False,\n",
    "                        legendgroup=model_name\n",
    "                    ),\n",
    "                    row=2, col=2\n",
    "                )\n",
    "                \n",
    "                # Add reference line\n",
    "                if model_name == list(residuals_data.keys())[0]:  # Add only once\n",
    "                    slope, intercept = np.polyfit(theoretical_quantiles, sorted_residuals, 1)\n",
    "                    line_y = slope * theoretical_quantiles + intercept\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=theoretical_quantiles,\n",
    "                            y=line_y,\n",
    "                            mode='lines',\n",
    "                            line=dict(color='red', dash='dash'),\n",
    "                            name=\"Reference Line\",\n",
    "                            showlegend=False\n",
    "                        ),\n",
    "                        row=2, col=2\n",
    "                    )\n",
    "\n",
    "        # 6. Residuals boxplot comparison\n",
    "        for model_name, data in residuals_data.items():\n",
    "            residuals = data[\"residuals\"].dropna().values\n",
    "            if len(residuals) > 0:\n",
    "                fig.add_trace(\n",
    "                    go.Box(\n",
    "                        y=residuals,\n",
    "                        name=model_name,\n",
    "                        marker=dict(color=self.colors.get(model_name.lower(), \"#95A5A6\")),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=2, col=3\n",
    "                )\n",
    "\n",
    "        # Add horizontal line at y=0\n",
    "        fig.add_hline(y=0, line_dash=\"dash\", line_color=\"red\", opacity=0.7, row=2, col=3)\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=800,\n",
    "            title_text=\"Residuals Diagnostic Panel\",\n",
    "            title_x=0.5,\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        # Update axes labels\n",
    "        fig.update_xaxes(title_text=\"Residuals\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Density\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Fitted Values\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Residuals\", row=1, col=2)\n",
    "        fig.update_xaxes(title_text=\"Fitted Values\", row=1, col=3)\n",
    "        fig.update_yaxes(title_text=\"√|Standardized Residuals|\", row=1, col=3)\n",
    "        fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Residuals\", row=2, col=1)\n",
    "        fig.update_xaxes(title_text=\"Theoretical Quantiles\", row=2, col=2)\n",
    "        fig.update_yaxes(title_text=\"Sample Quantiles\", row=2, col=2)\n",
    "        fig.update_yaxes(title_text=\"Residuals\", row=2, col=3)\n",
    "\n",
    "        if save_path:\n",
    "            fig.write_html(save_path)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def create_feature_importance_comparison(\n",
    "        self,\n",
    "        feature_importance_dict: Dict[str, Union[pd.DataFrame, pl.DataFrame]],\n",
    "        top_n: int = 15,\n",
    "        save_path: Optional[str] = None,\n",
    "    ) -> go.Figure:\n",
    "        \"\"\"Create enhanced feature importance comparison with consistency analysis.\"\"\"\n",
    "        \n",
    "        feature_importance_dict = {\n",
    "            k: v.to_pandas() if isinstance(v, pl.DataFrame) else v \n",
    "            for k, v in feature_importance_dict.items()\n",
    "        }\n",
    "\n",
    "        n_models = len(feature_importance_dict)\n",
    "        \n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=n_models + 1,\n",
    "            subplot_titles=list(feature_importance_dict.keys()) + [\"Feature Consistency\", \"Feature Importance Heatmap\"],\n",
    "            specs=[[{\"type\": \"bar\"}] * n_models + [{\"type\": \"bar\"}]] + \n",
    "                  [[{\"colspan\": n_models + 1, \"type\": \"heatmap\"}] + [None] * n_models],\n",
    "            vertical_spacing=0.15,\n",
    "            horizontal_spacing=0.05\n",
    "        )\n",
    "\n",
    "        # Individual model importance plots (top row)\n",
    "        for idx, (model_name, importance_df) in enumerate(feature_importance_dict.items()):\n",
    "            col = idx + 1\n",
    "            \n",
    "            top_features = importance_df.nlargest(top_n, \"importance\")\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    y=top_features[\"feature\"],\n",
    "                    x=top_features[\"importance\"],\n",
    "                    orientation='h',\n",
    "                    marker=dict(color=self.colors.get(model_name.lower(), \"#95A5A6\")),\n",
    "                    text=[f\"{v:.3f}\" for v in top_features[\"importance\"]],\n",
    "                    textposition=\"outside\",\n",
    "                    showlegend=False,\n",
    "                    name=f\"{model_name} Features\"\n",
    "                ),\n",
    "                row=1, col=col\n",
    "            )\n",
    "\n",
    "        # Feature consistency analysis (top right)\n",
    "        consistency_data = self._calculate_feature_consistency(feature_importance_dict, top_n)\n",
    "        if consistency_data:\n",
    "            features, counts = zip(*consistency_data.items())\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    y=list(features),\n",
    "                    x=list(counts),\n",
    "                    orientation='h',\n",
    "                    marker=dict(color=\"#4A90E2\"),\n",
    "                    showlegend=False,\n",
    "                    name=\"Feature Consistency\"\n",
    "                ),\n",
    "                row=1, col=n_models + 1\n",
    "            )\n",
    "\n",
    "        # Feature importance heatmap (bottom)\n",
    "        heatmap_data = self._create_importance_heatmap_data(feature_importance_dict, top_n)\n",
    "        if heatmap_data is not None:\n",
    "            importance_matrix, features, models = heatmap_data\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    z=importance_matrix,\n",
    "                    x=models,\n",
    "                    y=features,\n",
    "                    colorscale='RdYlBu_r',\n",
    "                    showscale=True,\n",
    "                    colorbar=dict(title=\"Normalized Importance\")\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=900,\n",
    "            title_text=f\"Feature Importance Analysis - Top {top_n} Features\",\n",
    "            title_x=0.5,\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "        if save_path:\n",
    "            fig.write_html(save_path)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def create_model_stability_analysis(\n",
    "        self,\n",
    "        predictions_dict: Dict[str, Union[pd.DataFrame, pl.DataFrame]],\n",
    "        actual_data: Union[pd.DataFrame, pl.DataFrame],\n",
    "        target_col: str = \"sales\",\n",
    "        window_size: int = 30,\n",
    "        save_path: Optional[str] = None,\n",
    "    ) -> go.Figure:\n",
    "        \"\"\"Create model stability analysis showing performance over time windows.\"\"\"\n",
    "        \n",
    "        if isinstance(actual_data, pl.DataFrame):\n",
    "            actual_data = actual_data.to_pandas()\n",
    "\n",
    "        predictions_dict = {\n",
    "            k: (v.to_pandas() if isinstance(v, pl.DataFrame) else v) \n",
    "            for k, v in predictions_dict.items()\n",
    "        }\n",
    "\n",
    "        # Calculate rolling metrics\n",
    "        stability_data = {}\n",
    "        for model_name, pred_df in predictions_dict.items():\n",
    "            merged = pd.merge(actual_data[[\"date\", target_col]], pred_df[[\"date\", \"prediction\"]], on=\"date\", how=\"inner\")\n",
    "            merged = merged.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "            rolling_mae = []\n",
    "            rolling_rmse = []\n",
    "            rolling_r2 = []\n",
    "            dates = []\n",
    "\n",
    "            for i in range(window_size, len(merged)):\n",
    "                window_actual = merged[target_col].iloc[i - window_size : i]\n",
    "                window_pred = merged[\"prediction\"].iloc[i - window_size : i]\n",
    "\n",
    "                mae = mean_absolute_error(window_actual, window_pred)\n",
    "                rmse = np.sqrt(mean_squared_error(window_actual, window_pred))\n",
    "                r2 = r2_score(window_actual, window_pred)\n",
    "\n",
    "                rolling_mae.append(mae)\n",
    "                rolling_rmse.append(rmse)\n",
    "                rolling_r2.append(r2)\n",
    "                dates.append(merged[\"date\"].iloc[i])\n",
    "\n",
    "            stability_data[model_name] = {\n",
    "                \"dates\": dates, \n",
    "                \"mae\": rolling_mae, \n",
    "                \"rmse\": rolling_rmse, \n",
    "                \"r2\": rolling_r2\n",
    "            }\n",
    "\n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=[\"Rolling MAE\", \"Rolling RMSE\", \"Rolling R²\", \"Model Stability Ranking\"],\n",
    "            vertical_spacing=0.12\n",
    "        )\n",
    "\n",
    "        # Plot rolling metrics\n",
    "        metrics_info = [(\"mae\", \"Rolling MAE\", 1, 1), (\"rmse\", \"Rolling RMSE\", 1, 2), (\"r2\", \"Rolling R²\", 2, 1)]\n",
    "\n",
    "        for metric, title, row, col in metrics_info:\n",
    "            for model_name, data in stability_data.items():\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=data[\"dates\"],\n",
    "                        y=data[metric],\n",
    "                        mode='lines',\n",
    "                        line=dict(color=self.colors.get(model_name.lower(), \"#95A5A6\"), width=2),\n",
    "                        name=model_name,\n",
    "                        showlegend=(row == 1 and col == 1),\n",
    "                        legendgroup=model_name\n",
    "                    ),\n",
    "                    row=row, col=col\n",
    "                )\n",
    "\n",
    "        # Model stability ranking (bottom right)\n",
    "        stability_ranking = self._calculate_stability_ranking(stability_data)\n",
    "        models_sorted = [x[0] for x in stability_ranking]\n",
    "        scores_sorted = [x[1] for x in stability_ranking]\n",
    "        colors_sorted = [self.colors.get(model.lower(), \"#95A5A6\") for model in models_sorted]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                y=models_sorted,\n",
    "                x=scores_sorted,\n",
    "                orientation='h',\n",
    "                marker=dict(color=colors_sorted),\n",
    "                text=[f\"{score:.3f}\" for score in scores_sorted],\n",
    "                textposition=\"outside\",\n",
    "                showlegend=False,\n",
    "                name=\"Stability Ranking\"\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=700,\n",
    "            title_text=f\"Model Stability Analysis (Rolling Window: {window_size})\",\n",
    "            title_x=0.5,\n",
    "            showlegend=True\n",
    "        )\n",
    "        \n",
    "        # Update axes\n",
    "        fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "        fig.update_xaxes(title_text=\"Date\", row=1, col=2)\n",
    "        fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "        fig.update_xaxes(title_text=\"Coefficient of Variation\", row=2, col=2)\n",
    "        fig.update_yaxes(title_text=\"MAE\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"RMSE\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"R²\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"Models\", row=2, col=2)\n",
    "\n",
    "        if save_path:\n",
    "            fig.write_html(save_path)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def create_comprehensive_report(\n",
    "        self,\n",
    "        metrics_dict: Dict[str, Dict[str, float]],\n",
    "        predictions_dict: Dict[str, Union[pd.DataFrame, pl.DataFrame]],\n",
    "        actual_data: Union[pd.DataFrame, pl.DataFrame],\n",
    "        feature_importance_dict: Optional[Dict[str, pd.DataFrame]] = None,\n",
    "        save_dir: str = \"/tmp/model_comparison_charts\",\n",
    "        window_size: int = 30,\n",
    "    ) -> Dict[str, str]:\n",
    "        \"\"\"Generate all comparison charts and save them.\"\"\"\n",
    "        \n",
    "        if isinstance(actual_data, pl.DataFrame):\n",
    "            actual_data = actual_data.to_pandas()\n",
    "\n",
    "        predictions_dict = {\n",
    "            k: (v.to_pandas() if isinstance(v, pl.DataFrame) else v) \n",
    "            for k, v in predictions_dict.items()\n",
    "        }\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        saved_files = {}\n",
    "\n",
    "        # 1. Performance Dashboard\n",
    "        fig1 = self.create_performance_dashboard(metrics_dict)\n",
    "        path1 = os.path.join(save_dir, \"performance_dashboard.html\")\n",
    "        fig1.write_html(path1)\n",
    "        saved_files[\"performance_dashboard\"] = path1\n",
    "\n",
    "        # 2. Prediction Quality Analysis\n",
    "        fig2 = self.create_prediction_quality_analysis(predictions_dict, actual_data)\n",
    "        path2 = os.path.join(save_dir, \"prediction_quality_analysis.html\")\n",
    "        fig2.write_html(path2)\n",
    "        saved_files[\"prediction_quality_analysis\"] = path2\n",
    "\n",
    "        # 3. Residuals Diagnostic Panel\n",
    "        fig3 = self.create_residuals_diagnostic_panel(predictions_dict, actual_data)\n",
    "        path3 = os.path.join(save_dir, \"residuals_diagnostic_panel.html\")\n",
    "        fig3.write_html(path3)\n",
    "        saved_files[\"residuals_diagnostic_panel\"] = path3\n",
    "\n",
    "        # 4. Model Stability Analysis (if enough data)\n",
    "        if len(actual_data) > window_size * 2:\n",
    "            fig4 = self.create_model_stability_analysis(predictions_dict, actual_data, window_size=window_size)\n",
    "            path4 = os.path.join(save_dir, \"model_stability_analysis.html\")\n",
    "            fig4.write_html(path4)\n",
    "            saved_files[\"model_stability_analysis\"] = path4\n",
    "\n",
    "        # 5. Feature Importance (if available)\n",
    "        if feature_importance_dict:\n",
    "            fig5 = self.create_feature_importance_comparison(feature_importance_dict)\n",
    "            path5 = os.path.join(save_dir, \"feature_importance_comparison.html\")\n",
    "            fig5.write_html(path5)\n",
    "            saved_files[\"feature_importance_comparison\"] = path5\n",
    "\n",
    "        return saved_files\n",
    "\n",
    "    # Helper methods\n",
    "    def _calculate_model_ranking(self, metrics_dict: Dict[str, Dict[str, float]]) -> list:\n",
    "        \"\"\"Calculate model ranking based on average rank across metrics.\"\"\"\n",
    "        models = list(metrics_dict.keys())\n",
    "        ranking_scores = {}\n",
    "\n",
    "        for model in models:\n",
    "            total_rank = 0\n",
    "\n",
    "            # For metrics where lower is better (RMSE, MAE, MAPE)\n",
    "            for metric in [\"rmse\", \"mae\", \"mape\"]:\n",
    "                values = [metrics_dict[m].get(metric, float(\"inf\")) for m in models]\n",
    "                sorted_values = sorted(values)\n",
    "                model_value = metrics_dict[model].get(metric, float(\"inf\"))\n",
    "                rank = sorted_values.index(model_value) + 1\n",
    "                total_rank += rank\n",
    "\n",
    "            # For R² - higher is better\n",
    "            r2_values = [metrics_dict[m].get(\"r2\", -float(\"inf\")) for m in models]\n",
    "            r2_sorted_desc = sorted(r2_values, reverse=True)\n",
    "            model_r2 = metrics_dict[model].get(\"r2\", -float(\"inf\"))\n",
    "            r2_rank = r2_sorted_desc.index(model_r2) + 1\n",
    "            total_rank += r2_rank\n",
    "\n",
    "            # Average rank across all 4 metrics\n",
    "            avg_rank = total_rank / 4\n",
    "            ranking_scores[model] = avg_rank\n",
    "\n",
    "        # Sort by ranking score (lowest average rank = best)\n",
    "        return sorted(ranking_scores.items(), key=lambda x: x[1])\n",
    "\n",
    "    def _calculate_normalized_performance(self, metrics_dict: Dict[str, Dict[str, float]]) -> Dict[str, list]:\n",
    "        \"\"\"Calculate normalized performance metrics.\"\"\"\n",
    "        models = list(metrics_dict.keys())\n",
    "        metrics = [\"rmse\", \"mae\", \"mape\", \"r2\"]\n",
    "        \n",
    "        normalized_data = {}\n",
    "        for metric in metrics:\n",
    "            values = [metrics_dict[model].get(metric, 0) for model in models]\n",
    "            if metric == \"r2\":  # Higher is better\n",
    "                min_val, max_val = min(values), max(values)\n",
    "                if max_val != min_val:\n",
    "                    normalized_values = [0.1 + 0.9 * (v - min_val) / (max_val - min_val) for v in values]\n",
    "                else:\n",
    "                    normalized_values = [0.55] * len(values)\n",
    "            else:  # Lower is better - invert\n",
    "                min_val, max_val = min(values), max(values)\n",
    "                if max_val != min_val:\n",
    "                    normalized_values = [0.1 + 0.9 * (1 - (v - min_val) / (max_val - min_val)) for v in values]\n",
    "                else:\n",
    "                    normalized_values = [0.55] * len(values)\n",
    "            \n",
    "            normalized_data[metric] = normalized_values\n",
    "\n",
    "        return normalized_data\n",
    "\n",
    "    def _calculate_feature_consistency(self, feature_importance_dict: Dict[str, pd.DataFrame], top_n: int) -> Dict[str, int]:\n",
    "        \"\"\"Calculate feature consistency across models.\"\"\"\n",
    "        all_features = set()\n",
    "        for df in feature_importance_dict.values():\n",
    "            all_features.update(df[\"feature\"].tolist())\n",
    "\n",
    "        feature_counts = {}\n",
    "        for feature in all_features:\n",
    "            count = 0\n",
    "            for df in feature_importance_dict.values():\n",
    "                top_features = df.nlargest(top_n, \"importance\")[\"feature\"].tolist()\n",
    "                if feature in top_features:\n",
    "                    count += 1\n",
    "            if count > 1:  # Only show features that appear in multiple models\n",
    "                feature_counts[feature] = count\n",
    "\n",
    "        return feature_counts\n",
    "\n",
    "    def _create_importance_heatmap_data(self, feature_importance_dict: Dict[str, pd.DataFrame], top_n: int):\n",
    "        \"\"\"Create data for feature importance heatmap.\"\"\"\n",
    "        # Get top features across all models\n",
    "        all_features = set()\n",
    "        for df in feature_importance_dict.values():\n",
    "            top_features = df.nlargest(top_n, \"importance\")[\"feature\"].tolist()\n",
    "            all_features.update(top_features)\n",
    "\n",
    "        if not all_features:\n",
    "            return None\n",
    "\n",
    "        # Create importance matrix\n",
    "        models = list(feature_importance_dict.keys())\n",
    "        features = list(all_features)\n",
    "        importance_matrix = np.zeros((len(features), len(models)))\n",
    "\n",
    "        for j, model in enumerate(models):\n",
    "            df = feature_importance_dict[model]\n",
    "            for i, feature in enumerate(features):\n",
    "                importance_row = df[df[\"feature\"] == feature]\n",
    "                if not importance_row.empty:\n",
    "                    importance_matrix[i, j] = importance_row[\"importance\"].iloc[0]\n",
    "\n",
    "        # Normalize by row (feature) for better visualization\n",
    "        importance_matrix_norm = importance_matrix / (importance_matrix.max(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "        return importance_matrix_norm, features, models\n",
    "\n",
    "    def _calculate_stability_ranking(self, stability_data: Dict[str, Dict]) -> list:\n",
    "        \"\"\"Calculate model stability ranking based on variance of rolling metrics.\"\"\"\n",
    "        stability_scores = {}\n",
    "\n",
    "        for model_name, data in stability_data.items():\n",
    "            # Calculate coefficient of variation (std/mean) for each metric\n",
    "            mae_cv = np.std(data[\"mae\"]) / (np.mean(data[\"mae\"]) + 1e-8)\n",
    "            rmse_cv = np.std(data[\"rmse\"]) / (np.mean(data[\"rmse\"]) + 1e-8)\n",
    "            r2_cv = np.std(data[\"r2\"]) / (np.mean(np.abs(data[\"r2\"])) + 1e-8)\n",
    "\n",
    "            # Average CV (lower is more stable)\n",
    "            stability_scores[model_name] = (mae_cv + rmse_cv + r2_cv) / 3\n",
    "\n",
    "        # Sort by stability (lower CV = more stable)\n",
    "        return sorted(stability_scores.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "# Example usage and compatibility function\n",
    "def generate_model_comparison_report_plotly(\n",
    "    run_id: str, \n",
    "    test_data: Union[pd.DataFrame, pl.DataFrame]\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Generate comparison report from MLflow run using Plotly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    run_id : str\n",
    "        MLflow run ID.\n",
    "    test_data : Union[pd.DataFrame, pl.DataFrame]\n",
    "        Test data with ground truth.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, str]\n",
    "        Dictionary of saved file paths.\n",
    "    \"\"\"\n",
    "    import mlflow\n",
    "    \n",
    "    if isinstance(test_data, pl.DataFrame):\n",
    "        test_data = test_data.to_pandas()\n",
    "\n",
    "    visualizer = PlotlyModelVisualizer()\n",
    "\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    run = client.get_run(run_id)\n",
    "\n",
    "    # Extract metrics\n",
    "    metrics_dict = {}\n",
    "    for model in [\"xgboost\", \"lightgbm\", \"ensemble\"]:\n",
    "        model_metrics = {}\n",
    "        for metric in [\"rmse\", \"mae\", \"mape\", \"r2\"]:\n",
    "            metric_key = f\"{model}_{metric}\"\n",
    "            if metric_key in run.data.metrics:\n",
    "                model_metrics[metric] = run.data.metrics[metric_key]\n",
    "        if model_metrics:\n",
    "            metrics_dict[model] = model_metrics\n",
    "\n",
    "    # Generate dummy predictions for visualization\n",
    "    predictions_dict = {}\n",
    "    rng = np.random.default_rng()\n",
    "    for model in metrics_dict.keys():\n",
    "        pred_df = test_data[[\"date\"]].copy()\n",
    "        noise = rng.normal(0, 5, len(test_data))\n",
    "        pred_df[\"prediction\"] = test_data[\"sales\"] + noise\n",
    "        predictions_dict[model] = pred_df\n",
    "\n",
    "    # Generate visualizations\n",
    "    saved_files = visualizer.create_comprehensive_report(metrics_dict, predictions_dict, test_data)\n",
    "\n",
    "    # Log visualizations to MLflow\n",
    "    for name, path in saved_files.items():\n",
    "        mlflow.log_artifact(path, f\"artifacts/visualizations/{name}\")\n",
    "\n",
    "    return saved_files\n",
    "\n",
    "\n",
    "# Example of creating sample data for testing\n",
    "def create_sample_data_for_testing():\n",
    "    \"\"\"Create sample data for testing the visualizer.\"\"\"\n",
    "    import datetime\n",
    "    \n",
    "    # Create sample actual data\n",
    "    dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "    np.random.seed(42)\n",
    "    sales = 100 + 10 * np.sin(2 * np.pi * np.arange(len(dates)) / 365) + np.random.normal(0, 5, len(dates))\n",
    "    \n",
    "    actual_data = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'sales': sales\n",
    "    })\n",
    "    \n",
    "    # Create sample metrics\n",
    "    metrics_dict = {\n",
    "        'xgboost': {'rmse': 5.2, 'mae': 4.1, 'mape': 8.5, 'r2': 0.85},\n",
    "        'lightgbm': {'rmse': 5.8, 'mae': 4.5, 'mape': 9.2, 'r2': 0.82},\n",
    "        'ensemble': {'rmse': 4.9, 'mae': 3.8, 'mape': 7.8, 'r2': 0.87}\n",
    "    }\n",
    "    \n",
    "    # Create sample predictions\n",
    "    predictions_dict = {}\n",
    "    for model in metrics_dict.keys():\n",
    "        pred_df = actual_data[['date']].copy()\n",
    "        noise_std = metrics_dict[model]['rmse'] * 0.8\n",
    "        pred_df['prediction'] = actual_data['sales'] + np.random.normal(0, noise_std, len(actual_data))\n",
    "        predictions_dict[model] = pred_df\n",
    "    \n",
    "    # Create sample feature importance\n",
    "    features = ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', \n",
    "               'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10']\n",
    "    \n",
    "    feature_importance_dict = {}\n",
    "    for model in metrics_dict.keys():\n",
    "        importance_values = np.random.exponential(scale=0.1, size=len(features))\n",
    "        importance_values = importance_values / importance_values.sum()  # Normalize\n",
    "        \n",
    "        feature_importance_dict[model] = pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': importance_values\n",
    "        })\n",
    "    \n",
    "    return metrics_dict, predictions_dict, actual_data, feature_importance_dict\n",
    "\n",
    "\n",
    "# Test the visualizer\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample data\n",
    "    metrics_dict, predictions_dict, actual_data, feature_importance_dict = create_sample_data_for_testing()\n",
    "    \n",
    "    # Initialize visualizer\n",
    "    visualizer = PlotlyModelVisualizer()\n",
    "    \n",
    "    # Generate all reports\n",
    "    saved_files = visualizer.create_comprehensive_report(\n",
    "        metrics_dict=metrics_dict,\n",
    "        predictions_dict=predictions_dict,\n",
    "        actual_data=actual_data,\n",
    "        feature_importance_dict=feature_importance_dict,\n",
    "        save_dir=\"./plotly_charts\"\n",
    "    )\n",
    "    \n",
    "    print(\"Generated files:\")\n",
    "    for name, path in saved_files.items():\n",
    "        print(f\"  {name}: {path}\")\n",
    "        \n",
    "    # You can also create individual charts\n",
    "    # fig1 = visualizer.create_performance_dashboard(metrics_dict)\n",
    "    # fig1.show()\n",
    "    \n",
    "    # fig2 = visualizer.create_prediction_quality_analysis(predictions_dict, actual_data)\n",
    "    # fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a93ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c9f7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db62b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eafaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9ffe527",
   "metadata": {},
   "source": [
    "## Docker Container Import Testing\n",
    "\n",
    "When working with the Airflow containers, imports work correctly when you run Python from the right directory.\n",
    "\n",
    "### ✅ Correct way to import in Airflow containers:\n",
    "\n",
    "```bash\n",
    "# Start container shell from the correct directory\n",
    "docker compose exec airflow-worker bash\n",
    "\n",
    "# You'll be in /opt/airflow - this is the correct working directory\n",
    "pwd  # Should show: /opt/airflow\n",
    "\n",
    "# Now run Python and import\n",
    "python\n",
    "```\n",
    "\n",
    "```python\n",
    "# These imports will work correctly:\n",
    "import pandas as pd\n",
    "from include.config import app_settings\n",
    "from include.utilities.data_gen import RealisticSalesDataGenerator\n",
    "\n",
    "# Test the imports\n",
    "print(\"All imports successful!\")\n",
    "print(\"MLFLOW_HOST:\", app_settings.MLFLOW_HOST)\n",
    "gen = RealisticSalesDataGenerator(start_date=\"2025-09-01\", end_date=\"2025-09-02\", seed=42)\n",
    "print(\"Data generator created:\", type(gen))\n",
    "```\n",
    "\n",
    "### ❌ Common mistake - don't do this:\n",
    "\n",
    "```bash\n",
    "# Don't cd into the include directory first\n",
    "cd include  # This breaks imports!\n",
    "python      # Imports will fail from here\n",
    "```\n",
    "\n",
    "### Why this happens:\n",
    "\n",
    "1. Our `PYTHONPATH` is set to `/opt/airflow/include`\n",
    "2. When you run `python` from `/opt/airflow/include`, Python adds `.` (current directory) to sys.path\n",
    "3. This creates a conflict where Python tries to import `include` from within itself\n",
    "4. The solution: always run Python from `/opt/airflow` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482512b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports in Docker container (run this to verify everything works)\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def test_docker_imports():\n",
    "    \"\"\"Test that imports work correctly in the Airflow container.\"\"\"\n",
    "\n",
    "    # Test command to run in the container\n",
    "    test_script = \"\"\"\n",
    "import sys\n",
    "import pandas as pd\n",
    "from include.config import app_settings\n",
    "from include.utilities.data_gen import RealisticSalesDataGenerator\n",
    "\n",
    "# Test results\n",
    "results = {\n",
    "    \"python_path_includes_include\": \"/opt/airflow/include\" in sys.path,\n",
    "    \"current_working_directory\": __import__(\"os\").getcwd(),\n",
    "    \"pandas_version\": pd.__version__,\n",
    "    \"mlflow_host\": app_settings.MLFLOW_HOST,\n",
    "    \"data_generator_created\": str(type(RealisticSalesDataGenerator(start_date=\"2025-09-01\", end_date=\"2025-09-02\", seed=42)))\n",
    "}\n",
    "\n",
    "import json\n",
    "print(json.dumps(results, indent=2))\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        # Run the test in the container\n",
    "        cmd = [\n",
    "            \"docker\",\n",
    "            \"compose\",\n",
    "            \"exec\",\n",
    "            \"-T\",\n",
    "            \"airflow-worker\",\n",
    "            \"python\",\n",
    "            \"-c\",\n",
    "            test_script,\n",
    "        ]\n",
    "\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, cwd=\"../\")\n",
    "\n",
    "        if result.returncode == 0:\n",
    "            test_results = json.loads(result.stdout.strip())\n",
    "            print(\"✅ Docker container import test PASSED!\")\n",
    "            print(\"\\nTest Results:\")\n",
    "            for key, value in test_results.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "            return True\n",
    "        print(\"❌ Docker container import test FAILED!\")\n",
    "        print(\"Error output:\", result.stderr)\n",
    "        return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to run Docker test: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Run the test\n",
    "test_docker_imports()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "End-to-end-Sale-Forecasting (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
